{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Feature Engineering: Encoding Categorical Variables</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GS5XcySVoXtc"
   },
   "source": [
    "What is Feature Engineering ?\n",
    "\n",
    "Feature engineering is a crucial step in the data pre-processing phase of machine learning, where data scientists and machine learning engineers create new features or modify existing ones to improve the performance of machine learning models. The goal of feature engineering is to provide the model with informative, non-redundant, and interpretable data that captures the underlying structure of the dataset. This process can significantly enhance model accuracy and performance by leveraging domain knowledge and mathematical transformations.\n",
    "\n",
    "Key Aspects of Feature Engineering Include:\n",
    "\n",
    "1. Creation of New Features: Involves generating new features from the existing data, which might be more relevant to the prediction task. This could include combining two or more features, extracting parts of a date-time stamp (like the day of the week, month, or year), or creating interaction terms that capture the relationship between different variables.\n",
    "\n",
    "2. Feature Transformation: Applying transformations to features to change their distribution or scale. Common transformations include normalization, standardization, log transformation, and power transformations. These are especially important for algorithms that assume data is normally distributed or algorithms sensitive to the scale of features, like k-nearest Neighbors (KNN) and gradient descent-based algorithms.\n",
    "\n",
    "3. Feature Selection: Identifying the most relevant features to use in model training. This involves removing irrelevant, redundant, or noisy data that can detract from model performance. Techniques for feature selection include filter methods, wrapper methods, and embedded methods.\n",
    "\n",
    "4. Feature Extraction: Techniques like Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), and t-distributed Stochastic Neighbour Embedding (t-SNE) are used to reduce the number of features in a dataset while retaining as much of the variance in the data as possible. This is particularly useful for high-dimensional data.\n",
    "\n",
    "5. Handling Missing Values: Developing strategies for dealing with missing data, such as imputation (filling in missing values with the mean, median, mode, or using more complex algorithms), or creating binary indicators that signal whether data was missing.\n",
    "\n",
    "6. Encoding Categorical Variables: Converting categorical variables into a form that can be provided to ML models to improve performance. This includes using techniques like one-hot encoding, label encoding, and target encoding.\n",
    "\n",
    "7. Working with different modalities: Feature engineering also includes applying all the above techniques to different modalities of data like temporal, textual and geospatial data.\n",
    "\n",
    "Feature engineering is often considered more of an art than a science, requiring creativity, intuition, and domain knowledge. The quality and relevance of the features used can often make a more significant difference in the performance of a machine learning model than the choice of model itself. It enables models to learn better from the data, leading to more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79cc7a12"
   },
   "source": [
    "Feature encoding is a crucial step in machine learning that transforms categorical data into a numerical format. This is essential because most machine learning algorithms require numerical input. By encoding categorical features, we convert them into a representation that preserves their information while making them compatible with these algorithms. Common encoding techniques include ordinal encoding, one-hot encoding, target encoding, and frequency encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e984764"
   },
   "source": [
    "Second is **Discretization**, in which we take continuous numerical data and convert it into categorical form by dividing it into bins. This process is also called **Binning**.\n",
    "\n",
    "Third, we will also learn to encode the target feature or output column using techniques like Label Encoding, Label Binarizer, and MultiLabel Binarizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb179311"
   },
   "source": [
    "Machine learning is all about data, which we majorly classify into two forms: numerical data and categorical data. Numerical data includes features like age, weight, and marks, while categorical data includes categories like gender and state. In categorical data, there are two types:\n",
    "\n",
    "1. **Ordinal data:** This is categorical data with an intrinsic order, like feedback ratings (poor, good, excellent). If there's an order in categorical data, we call it ordinal data.\n",
    "2. **Nominal data:** This is categorical data without an intrinsic order, like gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {
    "id": "L8ZBLoOW_0SL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {
    "id": "UKWvkryE_7M5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Feature Engineering\\Datasets\\customer.csv').drop(columns=['age','gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KsQngOXq_9Vb",
    "outputId": "b64cba79-f79e-4879-feb6-a0717da59860"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>education</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average</td>\n",
       "      <td>School</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poor</td>\n",
       "      <td>UG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review education purchased\n",
       "0  Average    School        No\n",
       "1     Poor        UG        No\n",
       "2     Good        PG        No\n",
       "3     Good        PG        No\n",
       "4  Average        UG        No"
      ]
     },
     "execution_count": 1875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XZLY-ur2CvS"
   },
   "source": [
    "### 1. Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiYN-YW_xIoi"
   },
   "source": [
    "Ordinal encoding is a data preprocessing technique used in machine learning to convert categorical variables that have a natural, ordered relationship into a numerical format. This method assigns a unique integer to each category based on its rank or position in that order.\n",
    "\n",
    "How Ordinal Encoding Works\n",
    "The core principle of ordinal encoding is to replace categorical labels with integers that preserve the inherent sequence of the data. For this to be effective, the variable must be ordinal, meaning its categories have a logical progression.\n",
    "\n",
    "For instance, consider a variable for clothing size. The categories \"Small,\" \"Medium,\" and \"Large\" have a clear order. Ordinal encoding would convert them as follows:\n",
    "\n",
    "- Small → 0\n",
    "\n",
    "- Medium → 1\n",
    "\n",
    "- Large → 2\n",
    "\n",
    "This numerical representation allows machine learning algorithms, which primarily operate on numbers, to interpret the hierarchical nature of the feature.\n",
    "\n",
    "When to Use Ordinal Encoding\n",
    "This technique is most appropriate under specific circumstances:\n",
    "\n",
    "- Presence of Inherent Order: It should only be used for categorical features where the categories have a meaningful, ranked relationship. Examples include educational levels (\"High School,\" \"Bachelor's,\" \"Master's\"), customer satisfaction ratings (\"Dissatisfied,\" \"Neutral,\" \"Satisfied\"), or economic status (\"Low,\" \"Medium,\" \"High\").\n",
    "\n",
    "- Tree-Based Models: Algorithms like Decision Trees, Random Forests, and Gradient Boosting are well-suited for ordinally encoded data. These models can effectively use the ordered nature of the integers to make splits and decisions.\n",
    "\n",
    "Key Assumptions and Limitations\n",
    "While useful, ordinal encoding operates on a crucial assumption that can also be its main limitation:\n",
    "\n",
    "- Assumption of Equal Intervals: The technique implicitly assumes that the numerical distance between each category is equal. For example, in the \"Small, Medium, Large\" mapping (0, 1, 2), a model might interpret the difference between \"Small\" and \"Medium\" as being the same as the difference between \"Medium\" and \"Large.\" This may not be true in reality and can mislead certain types of models, such as linear models or Support Vector Machines, which are sensitive to the magnitude of feature values.\n",
    "\n",
    "- Not for Nominal Data: It is unsuitable for nominal categorical variables, where no intrinsic order exists (e.g., colors like \"Red,\" \"Green,\" \"Blue\"). Applying ordinal encoding to such data would introduce a false and misleading order, likely harming the model's performance. For nominal data, techniques like one-hot encoding are preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {
    "id": "feDh3z9k_-RG"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {
    "id": "7EfNyVKzAXba"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:2], df.iloc[:,-1], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KjtJP07VBWB-",
    "outputId": "2eb8b4cc-34eb-46ab-cfbf-9da7b5c72520"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Poor</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Good</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Poor</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poor</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Average</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Good</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Average</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Poor</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Poor</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Poor</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Average</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Average</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Good</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Good</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Average</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Good</td>\n",
       "      <td>School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Poor</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Poor</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review education\n",
       "15     Poor        UG\n",
       "8   Average        UG\n",
       "18     Good    School\n",
       "14     Poor        PG\n",
       "44  Average        UG\n",
       "28     Poor    School\n",
       "41     Good        PG\n",
       "1      Poor        UG\n",
       "10     Good        UG\n",
       "3      Good        PG\n",
       "49     Good        UG\n",
       "21  Average        PG\n",
       "40     Good    School\n",
       "42     Good        PG\n",
       "48     Good        UG\n",
       "46     Poor        PG\n",
       "19     Poor        PG\n",
       "0   Average    School\n",
       "34  Average    School\n",
       "31     Poor    School\n",
       "17     Poor        UG\n",
       "9      Good        UG\n",
       "7      Poor    School\n",
       "22     Poor        PG\n",
       "39     Poor        PG\n",
       "29  Average        UG\n",
       "27     Poor        PG\n",
       "43     Poor        PG\n",
       "37  Average        PG\n",
       "33     Good        PG\n",
       "20  Average    School\n",
       "25     Good    School\n",
       "30  Average        UG\n",
       "47     Good        PG\n",
       "36     Good        UG\n",
       "4   Average        UG\n",
       "24  Average        PG\n",
       "23     Good    School\n",
       "45     Poor        PG\n",
       "16     Poor        UG"
      ]
     },
     "execution_count": 1878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "metadata": {
    "id": "H1GvrzlzBXaW"
   },
   "outputs": [],
   "source": [
    "# specify order\n",
    "oe = OrdinalEncoder(categories=[['Poor','Average','Good'],['School','UG','PG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1880,
   "metadata": {
    "id": "E5iHLC0gBgS_"
   },
   "outputs": [],
   "source": [
    "X_train = oe.fit_transform(X_train)\n",
    "X_test = oe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ffh1Qjd2Bspt",
    "outputId": "3c62af07-0b62-468b-81c9-c134718acdfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review  education\n",
       "15     0.0        1.0\n",
       "8      1.0        1.0\n",
       "18     2.0        0.0\n",
       "14     0.0        2.0\n",
       "44     1.0        1.0\n",
       "28     0.0        0.0\n",
       "41     2.0        2.0\n",
       "1      0.0        1.0\n",
       "10     2.0        1.0\n",
       "3      2.0        2.0\n",
       "49     2.0        1.0\n",
       "21     1.0        2.0\n",
       "40     2.0        0.0\n",
       "42     2.0        2.0\n",
       "48     2.0        1.0\n",
       "46     0.0        2.0\n",
       "19     0.0        2.0\n",
       "0      1.0        0.0\n",
       "34     1.0        0.0\n",
       "31     0.0        0.0\n",
       "17     0.0        1.0\n",
       "9      2.0        1.0\n",
       "7      0.0        0.0\n",
       "22     0.0        2.0\n",
       "39     0.0        2.0\n",
       "29     1.0        1.0\n",
       "27     0.0        2.0\n",
       "43     0.0        2.0\n",
       "37     1.0        2.0\n",
       "33     2.0        2.0\n",
       "20     1.0        0.0\n",
       "25     2.0        0.0\n",
       "30     1.0        1.0\n",
       "47     2.0        2.0\n",
       "36     2.0        1.0\n",
       "4      1.0        1.0\n",
       "24     1.0        2.0\n",
       "23     2.0        0.0\n",
       "45     0.0        2.0\n",
       "16     0.0        1.0"
      ]
     },
     "execution_count": 1881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b54zmN1HB-V5",
    "outputId": "a5f5103a-6c02-4ea4-f474-6b83251f6023"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Poor', 'Average', 'Good'], dtype=object),\n",
       " array(['School', 'UG', 'PG'], dtype=object)]"
      ]
     },
     "execution_count": 1882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1Hsj7BHCCD6",
    "outputId": "ea086688-8dfe-4ff8-9a82-ff36c1ed8a93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['review', 'education'], dtype=object)"
      ]
     },
     "execution_count": 1883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EujQrLVGCFaF",
    "outputId": "948b7572-d9d2-4183-e4e5-dcd62a60b5b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUmuArzBCJeK",
    "outputId": "878bd453-6133-4d6c-8d9b-c68a502f4a37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Poor', 'PG']], dtype=object)"
      ]
     },
     "execution_count": 1885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.inverse_transform(np.array([0,2]).reshape(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXo6XQj5DHTc",
    "outputId": "56d0c153-1cec-4f66-8caf-238c8462677d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['review', 'education'], dtype=object)"
      ]
     },
     "execution_count": 1886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "id": "7hqoCe-SJMHU",
    "outputId": "eb6341af-fb7e-4a30-f015-4db3d3e44605"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but OrdinalEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review  education\n",
       "0     0.0       -1.0"
      ]
     },
     "execution_count": 1887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set unknown value\n",
    "oe = OrdinalEncoder(categories=[['Poor','Average','Good'],['School','UG','PG']],\n",
    "                    handle_unknown='use_encoded_value',\n",
    "                    unknown_value=-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:2], df.iloc[:,-1], test_size=0.2)\n",
    "X_train = oe.fit_transform(X_train)\n",
    "oe.transform(np.array(['Poor','college']).reshape(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRhlaYgB17w4"
   },
   "source": [
    "Infrequent categories, often referred to as \"rare categories,\" are categories within a categorical variable that appear very seldom in the dataset. These categories are characterized by having a low frequency or count compared to other categories within the same feature.\n",
    "\n",
    "How to handle:\n",
    "\n",
    "- Aggregation: Combining rare categories into a single \"Other\" category to reduce the feature's cardinality and simplify the model.\n",
    "\n",
    "- Encoding with Special Treatment: Using encoding techniques that specifically account for the rarity of categories, such as setting a min_frequency or max_categories threshold in OrdinalEncoder, or employing target encoding where the influence of rare categories is mitigated.\n",
    "\n",
    "- Exclusion: In some cases, particularly when a category is extremely rare, it might be justified to exclude those data points from the analysis if it's believed they do not add value or could introduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTQMhiVfNIz7",
    "outputId": "fdeaf5bd-9e12-4a3b-8efa-c741827beeb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['dog'],\n",
       "       ['dog'],\n",
       "       ['dog'],\n",
       "       ['dog'],\n",
       "       ['dog'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['rabbit'],\n",
       "       ['snake'],\n",
       "       ['snake'],\n",
       "       ['snake'],\n",
       "       ['horse'],\n",
       "       ['horse']], dtype=object)"
      ]
     },
     "execution_count": 1888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling infrequent categories\n",
    "X = np.array([['dog'] * 5 + ['cat'] * 20 + ['rabbit'] * 10 +['snake'] * 3 + ['horse'] * 2], dtype=object).T\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL2rAS173ydm"
   },
   "source": [
    "### `max_categories` in OrdinalEncoder (with grouping)\n",
    "\n",
    "- **Purpose**: Limits the number of categories encoded for a column.\n",
    "- **How it works**:\n",
    "  - If a column has **more unique categories than `max_categories`**, the encoder keeps only the **most frequent categories**.\n",
    "  - All other less frequent categories are **grouped into an \"other\" category**.\n",
    "- **Example**:\n",
    "  - Column has categories: `A, B, C, D, E`\n",
    "  - `max_categories=3` → encoder keeps top 2 frequent categories (`A`, `B`) as-is.\n",
    "  - All remaining categories (`C, D, E`) are combined into **one \"other\" category**.\n",
    "- **Benefit**: Reduces complexity and prevents rare categories from affecting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "metadata": {
    "id": "88Ag6Wzz45-C"
   },
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(max_categories=3).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jE_APwgi6cNb",
    "outputId": "1fdae7a9-f3d6-4fe4-89d1-f39f48894624"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['dog', 'horse', 'snake'], dtype=object)]"
      ]
     },
     "execution_count": 1890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.infrequent_categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "5jI7v-NI69yZ",
    "outputId": "c1c94f5e-c219-4ca5-a297-ccf408b83147"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0\n",
       "0  0.0\n",
       "1  1.0\n",
       "2  2.0\n",
       "3  2.0"
      ]
     },
     "execution_count": 1891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(np.array([['cat','rabbit','snake','dog']]).reshape(4,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUMTF02Q4-sH"
   },
   "source": [
    "### `min_frequency` in OrdinalEncoder\n",
    "\n",
    "- **Purpose**: Groups together *rare categories* based on how often they appear in the data.\n",
    "- **How it works**:\n",
    "  - Instead of specifying a fixed number of top categories (like `max_categories`),\n",
    "    you set a **minimum occurrence threshold**.\n",
    "  - Any category that appears **less than the given threshold** is combined into a single\n",
    "    **\"other\" category**.\n",
    "- **Parameter options**:\n",
    "  - An **integer** (e.g., `6`) → categories with counts **≥ 6** are kept; all others grouped as “other”.\n",
    "  - A **float** between `0` and `1` → treated as a fraction of the total sample size\n",
    "    (e.g., `0.05` keeps categories that occur in at least 5% of the rows).\n",
    "- **Benefit**: Automatically handles rare or noisy categories without manually counting them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBsp7bxK7MCI",
    "outputId": "4dcadfa8-1d51-4419-f684-f44a2569b570"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['horse', 'snake'], dtype=object)]"
      ]
     },
     "execution_count": 1892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder(min_frequency=4).fit(X)\n",
    "enc.infrequent_categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6ffIwLzB7X0X",
    "outputId": "f79e9786-b0cd-42bc-b930-ccf0e1cfed36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0\n",
       "0  0.0\n",
       "1  2.0\n",
       "2  3.0\n",
       "3  1.0\n",
       "4  3.0"
      ]
     },
     "execution_count": 1893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(np.array([['cat','rabbit','snake','dog','horse']]).reshape(5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1894,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwLXweWC53JO",
    "outputId": "62718292-10d7-42d3-8914-0ed9023845d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x0\n",
      "0  0.0\n",
      "1 -1.0\n",
      "2  1.0\n",
      "3  2.0\n",
      "4 -1.0\n"
     ]
    }
   ],
   "source": [
    "# handling missing data\n",
    "\n",
    "# Example categorical data with missing values\n",
    "data = [['Cat'], [np.nan], ['Dog'], ['Fish'], [np.nan]]\n",
    "\n",
    "# Setting encoded_missing_value to -1, indicating we want missing values to be encoded as -1\n",
    "encoder = OrdinalEncoder(encoded_missing_value=-1)\n",
    "\n",
    "encoded_data = encoder.fit_transform(data)\n",
    "\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUSPx3IOqsTp"
   },
   "source": [
    "### Label Encoder\n",
    "\n",
    "- **Purpose**: Encodes the **target/output feature** in classification problems.\n",
    "- **Key Points**:\n",
    "  - Not used for input features; it is **target/label encoding**, not feature encoding.\n",
    "  - Converts categorical labels into **integer values**.\n",
    "  - Useful when the output column contains categories like `['cat', 'dog', 'mouse']`.\n",
    "- **Example Mapping**:\n",
    "\n",
    "| Original Label | Encoded Value |\n",
    "|----------------|---------------|\n",
    "| cat            | 0             |\n",
    "| dog            | 1             |\n",
    "| mouse          | 2             |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1895,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4E4Nu6paOplS",
    "outputId": "b95c529a-8fcc-4378-8fd9-97197008bf92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>education</th>\n",
       "      <th>purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average</td>\n",
       "      <td>School</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poor</td>\n",
       "      <td>UG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good</td>\n",
       "      <td>PG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average</td>\n",
       "      <td>UG</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review education purchased\n",
       "0  Average    School        No\n",
       "1     Poor        UG        No\n",
       "2     Good        PG        No\n",
       "3     Good        PG        No\n",
       "4  Average        UG        No"
      ]
     },
     "execution_count": 1895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1896,
   "metadata": {
    "id": "8Sh0XzJi8DDg"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,0:2], df.iloc[:,-1], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1897,
   "metadata": {
    "id": "qC6QlpTQAe0M"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1898,
   "metadata": {
    "id": "p5UmmF44Ajgo"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1899,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AzfcZDHVAt-G",
    "outputId": "792727d5-fe0f-4d5c-c4bd-a1960efdffcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 1899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1900,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOQVF8_FA-8_",
    "outputId": "541ef4a9-a7d3-4b2f-99b8-5975682378c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 1900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(np.array([1,1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i13exhhYS3rx"
   },
   "source": [
    "### 2. OneHotEncoder\n",
    "\n",
    "- **Purpose**: Used for **categorical input features** that are **nominal**, i.e., have **no intrinsic order**.  \n",
    "  Examples: `brand` = ['Samsung', 'Apple', 'OnePlus']\n",
    "\n",
    "- **Why not use Ordinal Encoding here?**\n",
    "  - Ordinal encoding assigns integer values based on order.\n",
    "  - For nominal data, integers can mislead algorithms into thinking some categories are \"greater\" or \"more important.\"\n",
    "  - Some algorithms may give **unintended weight** to certain categories.\n",
    "\n",
    "- **How OneHotEncoder works**:\n",
    "  - For each category in a feature, a **new binary column** is created.\n",
    "  - If a row has that category, the column gets `1`; otherwise, `0`.\n",
    "  - Example:\n",
    "\n",
    "| brand      | brand_Samsung | brand_Apple | brand_OnePlus |\n",
    "|------------|---------------|-------------|---------------|\n",
    "| Samsung    | 1             | 0           | 0             |\n",
    "| Apple      | 0             | 1           | 0             |\n",
    "| OnePlus    | 0             | 0           | 1             |\n",
    "\n",
    "- **Key Points**:\n",
    "  - If a feature has `n` categories, it creates **n new features** (can also use `drop='first'` to avoid dummy variable trap).\n",
    "  - Produces a **sparse matrix** (mostly zeros).\n",
    "  - Called **\"one-hot\"** because only **one column has 1** for each row, rest are 0.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1901,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d7w0vV6VBCsy",
    "outputId": "c1848304-5ea3-4e39-a0a6-f81bd7904cda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\F'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\F'\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_22764\\800869964.py:1: SyntaxWarning: invalid escape sequence '\\F'\n",
      "  cars = pd.read_csv('C:\\Feature Engineering\\Datasets\\cars.csv').drop(columns=['km_driven','owner'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>fuel</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand    fuel  selling_price\n",
       "0   Maruti  Diesel         450000\n",
       "1    Skoda  Diesel         370000\n",
       "2    Honda  Petrol         158000\n",
       "3  Hyundai  Diesel         225000\n",
       "4   Maruti  Petrol         130000"
      ]
     },
     "execution_count": 1901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('C:\\Feature Engineering\\Datasets\\cars.csv').drop(columns=['km_driven','owner'])\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "sfdxAz4XZRpI",
    "outputId": "1c1ad7a6-504e-405c-e5ae-d02b758f4e39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand            0\n",
       "fuel             0\n",
       "selling_price    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {
    "id": "hRpOPGsJS_BI"
   },
   "outputs": [],
   "source": [
    "X = cars.iloc[:,0:2]\n",
    "y = cars.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {
    "id": "yy71HbwwTZJw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "RC9uo5zxTk14",
    "outputId": "92e97877-62e6-4255-da58-138ed85fc341"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>Tata</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>Mahindra</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>Maruti</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6502 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand    fuel\n",
       "6518      Tata  Petrol\n",
       "6144     Honda  Petrol\n",
       "6381   Hyundai  Diesel\n",
       "438     Maruti  Diesel\n",
       "5939    Maruti  Petrol\n",
       "...        ...     ...\n",
       "5226  Mahindra  Diesel\n",
       "5390    Maruti  Diesel\n",
       "860    Hyundai  Petrol\n",
       "7603    Maruti  Diesel\n",
       "7270    Maruti  Petrol\n",
       "\n",
       "[6502 rows x 2 columns]"
      ]
     },
     "execution_count": 1905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {
    "id": "zeeABX5bTl-P"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {
    "id": "_cNsyeXSTthx"
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {
    "id": "lso6XwecTxVI"
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "xFVXep46T0Lb",
    "outputId": "8a9b2336-50a1-4902-e9f5-dcf065b4d833"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_Ambassador</th>\n",
       "      <th>brand_Ashok</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Chevrolet</th>\n",
       "      <th>brand_Daewoo</th>\n",
       "      <th>brand_Datsun</th>\n",
       "      <th>brand_Fiat</th>\n",
       "      <th>brand_Force</th>\n",
       "      <th>brand_Ford</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_Renault</th>\n",
       "      <th>brand_Skoda</th>\n",
       "      <th>brand_Tata</th>\n",
       "      <th>brand_Toyota</th>\n",
       "      <th>brand_Volkswagen</th>\n",
       "      <th>brand_Volvo</th>\n",
       "      <th>fuel_CNG</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_LPG</th>\n",
       "      <th>fuel_Petrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6502 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_Ambassador  brand_Ashok  brand_Audi  brand_BMW  brand_Chevrolet  \\\n",
       "6518               0.0          0.0         0.0        0.0              0.0   \n",
       "6144               0.0          0.0         0.0        0.0              0.0   \n",
       "6381               0.0          0.0         0.0        0.0              0.0   \n",
       "438                0.0          0.0         0.0        0.0              0.0   \n",
       "5939               0.0          0.0         0.0        0.0              0.0   \n",
       "...                ...          ...         ...        ...              ...   \n",
       "5226               0.0          0.0         0.0        0.0              0.0   \n",
       "5390               0.0          0.0         0.0        0.0              0.0   \n",
       "860                0.0          0.0         0.0        0.0              0.0   \n",
       "7603               0.0          0.0         0.0        0.0              0.0   \n",
       "7270               0.0          0.0         0.0        0.0              0.0   \n",
       "\n",
       "      brand_Daewoo  brand_Datsun  brand_Fiat  brand_Force  brand_Ford  ...  \\\n",
       "6518           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "6144           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "6381           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "438            0.0           0.0         0.0          0.0         0.0  ...   \n",
       "5939           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "...            ...           ...         ...          ...         ...  ...   \n",
       "5226           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "5390           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "860            0.0           0.0         0.0          0.0         0.0  ...   \n",
       "7603           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "7270           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "\n",
       "      brand_Renault  brand_Skoda  brand_Tata  brand_Toyota  brand_Volkswagen  \\\n",
       "6518            0.0          0.0         1.0           0.0               0.0   \n",
       "6144            0.0          0.0         0.0           0.0               0.0   \n",
       "6381            0.0          0.0         0.0           0.0               0.0   \n",
       "438             0.0          0.0         0.0           0.0               0.0   \n",
       "5939            0.0          0.0         0.0           0.0               0.0   \n",
       "...             ...          ...         ...           ...               ...   \n",
       "5226            0.0          0.0         0.0           0.0               0.0   \n",
       "5390            0.0          0.0         0.0           0.0               0.0   \n",
       "860             0.0          0.0         0.0           0.0               0.0   \n",
       "7603            0.0          0.0         0.0           0.0               0.0   \n",
       "7270            0.0          0.0         0.0           0.0               0.0   \n",
       "\n",
       "      brand_Volvo  fuel_CNG  fuel_Diesel  fuel_LPG  fuel_Petrol  \n",
       "6518          0.0       0.0          0.0       0.0          1.0  \n",
       "6144          0.0       0.0          0.0       0.0          1.0  \n",
       "6381          0.0       0.0          1.0       0.0          0.0  \n",
       "438           0.0       0.0          1.0       0.0          0.0  \n",
       "5939          0.0       0.0          0.0       0.0          1.0  \n",
       "...           ...       ...          ...       ...          ...  \n",
       "5226          0.0       0.0          1.0       0.0          0.0  \n",
       "5390          0.0       0.0          1.0       0.0          0.0  \n",
       "860           0.0       0.0          0.0       0.0          1.0  \n",
       "7603          0.0       0.0          1.0       0.0          0.0  \n",
       "7270          0.0       0.0          0.0       0.0          1.0  \n",
       "\n",
       "[6502 rows x 36 columns]"
      ]
     },
     "execution_count": 1909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = ohe.fit_transform(X_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FX8L7MAST7Hj",
    "outputId": "df00b0cc-7e62-4d84-996c-93e795434959"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6502, 36)"
      ]
     },
     "execution_count": 1910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fk69sXkJT_wM",
    "outputId": "e255a76a-bf4f-4a2a-919f-b8a12f2f852e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Ambassador', 'Ashok', 'Audi', 'BMW', 'Chevrolet', 'Daewoo',\n",
       "        'Datsun', 'Fiat', 'Force', 'Ford', 'Honda', 'Hyundai', 'Isuzu',\n",
       "        'Jaguar', 'Jeep', 'Kia', 'Land', 'Lexus', 'MG', 'Mahindra',\n",
       "        'Maruti', 'Mercedes-Benz', 'Mitsubishi', 'Nissan', 'Opel',\n",
       "        'Peugeot', 'Renault', 'Skoda', 'Tata', 'Toyota', 'Volkswagen',\n",
       "        'Volvo'], dtype=object),\n",
       " array(['CNG', 'Diesel', 'LPG', 'Petrol'], dtype=object)]"
      ]
     },
     "execution_count": 1911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyb0qDeTUGQQ",
    "outputId": "fb9ab6ef-3bfc-4543-e3a1-9b860ae8a6ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brand', 'fuel'], dtype=object)"
      ]
     },
     "execution_count": 1912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGf_ndciUMbW",
    "outputId": "b019607d-3f9d-4129-b3af-e9697af2897e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApYyWl8Q66Nn",
    "outputId": "6ab767a3-9d33-476e-bee0-0197a7d9904e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brand_Ambassador', 'brand_Ashok', 'brand_Audi', 'brand_BMW',\n",
       "       'brand_Chevrolet', 'brand_Daewoo', 'brand_Datsun', 'brand_Fiat',\n",
       "       'brand_Force', 'brand_Ford', 'brand_Honda', 'brand_Hyundai',\n",
       "       'brand_Isuzu', 'brand_Jaguar', 'brand_Jeep', 'brand_Kia',\n",
       "       'brand_Land', 'brand_Lexus', 'brand_MG', 'brand_Mahindra',\n",
       "       'brand_Maruti', 'brand_Mercedes-Benz', 'brand_Mitsubishi',\n",
       "       'brand_Nissan', 'brand_Opel', 'brand_Peugeot', 'brand_Renault',\n",
       "       'brand_Skoda', 'brand_Tata', 'brand_Toyota', 'brand_Volkswagen',\n",
       "       'brand_Volvo', 'fuel_CNG', 'fuel_Diesel', 'fuel_LPG',\n",
       "       'fuel_Petrol'], dtype=object)"
      ]
     },
     "execution_count": 1914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "xltYeyMD6mlc",
    "outputId": "216827be-66ab-4824-ad14-6d71668c52e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_Ambassador</th>\n",
       "      <th>brand_Ashok</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Chevrolet</th>\n",
       "      <th>brand_Daewoo</th>\n",
       "      <th>brand_Datsun</th>\n",
       "      <th>brand_Fiat</th>\n",
       "      <th>brand_Force</th>\n",
       "      <th>brand_Ford</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_Renault</th>\n",
       "      <th>brand_Skoda</th>\n",
       "      <th>brand_Tata</th>\n",
       "      <th>brand_Toyota</th>\n",
       "      <th>brand_Volkswagen</th>\n",
       "      <th>brand_Volvo</th>\n",
       "      <th>fuel_CNG</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_LPG</th>\n",
       "      <th>fuel_Petrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6502 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      brand_Ambassador  brand_Ashok  brand_Audi  brand_BMW  brand_Chevrolet  \\\n",
       "6518               0.0          0.0         0.0        0.0              0.0   \n",
       "6144               0.0          0.0         0.0        0.0              0.0   \n",
       "6381               0.0          0.0         0.0        0.0              0.0   \n",
       "438                0.0          0.0         0.0        0.0              0.0   \n",
       "5939               0.0          0.0         0.0        0.0              0.0   \n",
       "...                ...          ...         ...        ...              ...   \n",
       "5226               0.0          0.0         0.0        0.0              0.0   \n",
       "5390               0.0          0.0         0.0        0.0              0.0   \n",
       "860                0.0          0.0         0.0        0.0              0.0   \n",
       "7603               0.0          0.0         0.0        0.0              0.0   \n",
       "7270               0.0          0.0         0.0        0.0              0.0   \n",
       "\n",
       "      brand_Daewoo  brand_Datsun  brand_Fiat  brand_Force  brand_Ford  ...  \\\n",
       "6518           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "6144           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "6381           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "438            0.0           0.0         0.0          0.0         0.0  ...   \n",
       "5939           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "...            ...           ...         ...          ...         ...  ...   \n",
       "5226           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "5390           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "860            0.0           0.0         0.0          0.0         0.0  ...   \n",
       "7603           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "7270           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "\n",
       "      brand_Renault  brand_Skoda  brand_Tata  brand_Toyota  brand_Volkswagen  \\\n",
       "6518            0.0          0.0         1.0           0.0               0.0   \n",
       "6144            0.0          0.0         0.0           0.0               0.0   \n",
       "6381            0.0          0.0         0.0           0.0               0.0   \n",
       "438             0.0          0.0         0.0           0.0               0.0   \n",
       "5939            0.0          0.0         0.0           0.0               0.0   \n",
       "...             ...          ...         ...           ...               ...   \n",
       "5226            0.0          0.0         0.0           0.0               0.0   \n",
       "5390            0.0          0.0         0.0           0.0               0.0   \n",
       "860             0.0          0.0         0.0           0.0               0.0   \n",
       "7603            0.0          0.0         0.0           0.0               0.0   \n",
       "7270            0.0          0.0         0.0           0.0               0.0   \n",
       "\n",
       "      brand_Volvo  fuel_CNG  fuel_Diesel  fuel_LPG  fuel_Petrol  \n",
       "6518          0.0       0.0          0.0       0.0          1.0  \n",
       "6144          0.0       0.0          0.0       0.0          1.0  \n",
       "6381          0.0       0.0          1.0       0.0          0.0  \n",
       "438           0.0       0.0          1.0       0.0          0.0  \n",
       "5939          0.0       0.0          0.0       0.0          1.0  \n",
       "...           ...       ...          ...       ...          ...  \n",
       "5226          0.0       0.0          1.0       0.0          0.0  \n",
       "5390          0.0       0.0          1.0       0.0          0.0  \n",
       "860           0.0       0.0          0.0       0.0          1.0  \n",
       "7603          0.0       0.0          1.0       0.0          0.0  \n",
       "7270          0.0       0.0          0.0       0.0          1.0  \n",
       "\n",
       "[6502 rows x 36 columns]"
      ]
     },
     "execution_count": 1915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = X_train,columns = ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFH7glrZVcJ6",
    "outputId": "62fb0ff6-0ab2-4ef5-e5f0-0ca8a72e3127"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Mercedes-Benz', 'Petrol']], dtype=object)"
      ]
     },
     "execution_count": 1916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.inverse_transform(np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "       0., 0. , 0. , 1.]).reshape(1,36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhQDcV_X-6_z"
   },
   "source": [
    "# The Dummy Variable Trap\n",
    "\n",
    "The **Dummy Variable Trap** is a scenario where features created by one-hot encoding are perfectly correlated. This perfect correlation, known as **perfect multicollinearity**, can be a problem for statistical models that expect features to be independent, such as Linear and Logistic Regression.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Does It Happen?\n",
    "\n",
    "When we one-hot encode a categorical feature with '$k$' categories, we create '$k$' new binary columns (dummy variables). The trap occurs because the information in these '$k$' columns is redundant—the value of any one column can be perfectly predicted from the values of the others.\n",
    "\n",
    "For example, if we have a feature \"Season\" with four categories (Winter, Spring, Summer, Fall), we create four dummy variables.\n",
    "\n",
    "| Season_Winter | Season_Spring | Season_Summer | Season_Fall |\n",
    "| :-----------: | :-----------: | :-----------: | :-----------: |\n",
    "|       1       |       0       |       0       |       0       |\n",
    "|       0       |       1       |       0       |       0       |\n",
    "|       0       |       0       |       1       |       0       |\n",
    "\n",
    "If a row is not Winter, Spring, or Summer, it *must* be Fall. This means:\n",
    "\n",
    "Season_Winter + Season_Spring + Season_Summer + Season_Fall = 1\n",
    "\n",
    "This perfect relationship confuses linear models because they can't determine the independent influence of each category on the outcome.\n",
    "\n",
    "---\n",
    "\n",
    "## The Solution: Drop One Column\n",
    "\n",
    "The solution is simple: for a feature with '$k$' categories, we only use **$k-1$** dummy variables.\n",
    "\n",
    "We drop one of the columns. The dropped category becomes the **baseline** or **reference category**. Its effect is captured by the model's intercept, and it is represented by a row where all the other dummy variables for that feature are zero.\n",
    "\n",
    "**Example (Dropping `Season_Fall`):**\n",
    "\n",
    "| Original | Season_Winter | Season_Spring | Season_Summer | Interpretation                       |\n",
    "| :------: | :-----------: | :-----------: | :-----------: | ------------------------------------ |\n",
    "|  Winter  |       1       |       0       |       0       | It is Winter.                        |\n",
    "|  Spring  |       0       |       1       |       0       | It is Spring.                        |\n",
    "|  Summer  |       0       |       0       |       1       | It is Summer.                        |\n",
    "|   Fall   |     **0** |     **0** |     **0** | It is not Winter, Spring, or Summer. |\n",
    "\n",
    "---\n",
    "\n",
    "## When Should You Care ?\n",
    "\n",
    "You primarily need to worry about the dummy variable trap when using models that are sensitive to multicollinearity.\n",
    "\n",
    "* **Affected Models:**\n",
    "    * Linear Regression\n",
    "    * Logistic Regression\n",
    "    * Linear Discriminant Analysis (LDA)\n",
    "\n",
    "* **Unaffected Models:**\n",
    "    * Decision Trees\n",
    "    * Random Forest\n",
    "    * XGBoost / Gradient Boosting\n",
    "    * K-Nearest Neighbors (KNN)\n",
    "\n",
    "Tree-based models are generally immune because they select features one at a time and do not rely on the same mathematical assumptions as linear models.\n",
    "\n",
    "---\n",
    "\n",
    "## Practical Implementation\n",
    "\n",
    "Most data science libraries have a simple parameter to handle this automatically:\n",
    "\n",
    "* **Pandas:** `pd.get_dummies(df, drop_first=True)`\n",
    "* **Scikit-learn:** `OneHotEncoder(drop='first')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCpKS7RrWCNQ",
    "outputId": "7f41bea2-4130-48b3-a1ac-79d7885cb86d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6502, 34)"
      ]
     },
     "execution_count": 1917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cars.iloc[:,0:2]\n",
    "y = cars.iloc[:,-1]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "ohe = OneHotEncoder(drop='first',sparse_output=False)\n",
    "ohe.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kb7QX83oWJmV",
    "outputId": "f66f34ed-8b4c-456a-8e76-f2eb21a01a78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0], dtype=object)"
      ]
     },
     "execution_count": 1918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.drop_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kcyHtYTxfCfM",
    "outputId": "f19ce35e-a59e-4e9c-8942-9b523ec8aaa6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand\n",
       "Maruti           1953\n",
       "Hyundai          1127\n",
       "Mahindra          635\n",
       "Tata              586\n",
       "Toyota            391\n",
       "Honda             369\n",
       "Ford              320\n",
       "Chevrolet         185\n",
       "Renault           183\n",
       "Volkswagen        154\n",
       "BMW                96\n",
       "Skoda              82\n",
       "Nissan             62\n",
       "Jaguar             59\n",
       "Volvo              54\n",
       "Datsun             48\n",
       "Mercedes-Benz      43\n",
       "Fiat               35\n",
       "Audi               30\n",
       "Jeep               26\n",
       "Lexus              22\n",
       "Mitsubishi         13\n",
       "Force               6\n",
       "Land                5\n",
       "Kia                 4\n",
       "Daewoo              3\n",
       "MG                  3\n",
       "Ambassador          3\n",
       "Isuzu               2\n",
       "Ashok               1\n",
       "Peugeot             1\n",
       "Opel                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling rare categories\n",
    "X_train['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Td8WNyX_gKaa",
    "outputId": "058da76a-982f-4100-a616-757b9cebb68e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fuel\n",
       "Diesel    4402\n",
       "Petrol    3631\n",
       "CNG         57\n",
       "LPG         38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars['fuel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kgL8yf7gOs8",
    "outputId": "86e45ff7-122b-4c78-cc4f-5f598a1c4e43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6502, 14)"
      ]
     },
     "execution_count": 1921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using min frequency\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, min_frequency=100)\n",
    "ohe.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnwwhRCegvex",
    "outputId": "8eb48381-3d76-4bef-c369-0e23e948b8e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brand_Chevrolet', 'brand_Ford', 'brand_Honda', 'brand_Hyundai',\n",
       "       'brand_Mahindra', 'brand_Maruti', 'brand_Renault', 'brand_Tata',\n",
       "       'brand_Toyota', 'brand_Volkswagen', 'brand_infrequent_sklearn',\n",
       "       'fuel_Diesel', 'fuel_Petrol', 'fuel_infrequent_sklearn'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 1922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvIkPQjug8XV",
    "outputId": "fbf97fe7-c0ff-4bb4-e4ad-741ee9f6ba00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6502, 19)"
      ]
     },
     "execution_count": 1923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_categories\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore', max_categories=15)\n",
    "ohe.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yM143eHhcK-",
    "outputId": "552cbf81-b338-4a3a-f0bf-6d13b07a798f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['brand_BMW', 'brand_Chevrolet', 'brand_Ford', 'brand_Honda',\n",
       "       'brand_Hyundai', 'brand_Jaguar', 'brand_Mahindra', 'brand_Maruti',\n",
       "       'brand_Nissan', 'brand_Renault', 'brand_Skoda', 'brand_Tata',\n",
       "       'brand_Toyota', 'brand_Volkswagen', 'brand_infrequent_sklearn',\n",
       "       'fuel_CNG', 'fuel_Diesel', 'fuel_LPG', 'fuel_Petrol'], dtype=object)"
      ]
     },
     "execution_count": 1924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNDpWvVuC4zs"
   },
   "source": [
    "### Handling Unknown Categories During Prediction (OneHotEncoder)\n",
    "\n",
    "- **Context**:  \n",
    "  After training a model, the **OneHotEncoder** is used again during prediction  \n",
    "  (e.g., when transforming new test data or live user inputs).  \n",
    "  Sometimes, the new data may contain a **category that was never seen** during training.\n",
    "\n",
    "- **Default Behavior (`handle_unknown='error')**:  \n",
    "  - If a new category appears during prediction, the encoder will raise a **ValueError**.\n",
    "  - Example:\n",
    "    - Training categories: `Red`, `Blue`, `Green`\n",
    "    - Prediction data contains: `Yellow`\n",
    "    -  Error: `Found unknown categories ['Yellow'] in column 0 during transform`\n",
    "\n",
    "- **Safe Option (`handle_unknown='ignore')**:  \n",
    "  - When creating the encoder, set:\n",
    "    ```python\n",
    "    OneHotEncoder(handle_unknown='ignore')\n",
    "    ```\n",
    "  - During prediction, any unseen category is encoded as **all zeros** across the dummy columns.\n",
    "  - Example:\n",
    "    - Training categories: `Red`, `Blue`, `Green`\n",
    "    - Prediction contains: `Yellow`\n",
    "    - Encoding for `Yellow` → `[0, 0, 0]`\n",
    "\n",
    "- **Key Takeaways**:\n",
    "  - Always fit the encoder on the **training data only**, and then reuse it for prediction.\n",
    "  - `handle_unknown='ignore'` ensures the model will **not crash** when a new category appears.\n",
    "  - The model interprets an all-zero vector as a **neutral signal** (no known category matched).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "_sveyEXElp2y",
    "outputId": "7f27998a-0e09-47ae-b5eb-fd338f08c563"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_Ambassador</th>\n",
       "      <th>brand_Ashok</th>\n",
       "      <th>brand_Audi</th>\n",
       "      <th>brand_BMW</th>\n",
       "      <th>brand_Chevrolet</th>\n",
       "      <th>brand_Daewoo</th>\n",
       "      <th>brand_Datsun</th>\n",
       "      <th>brand_Fiat</th>\n",
       "      <th>brand_Force</th>\n",
       "      <th>brand_Ford</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_Renault</th>\n",
       "      <th>brand_Skoda</th>\n",
       "      <th>brand_Tata</th>\n",
       "      <th>brand_Toyota</th>\n",
       "      <th>brand_Volkswagen</th>\n",
       "      <th>brand_Volvo</th>\n",
       "      <th>fuel_CNG</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_LPG</th>\n",
       "      <th>fuel_Petrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_Ambassador  brand_Ashok  brand_Audi  brand_BMW  brand_Chevrolet  \\\n",
       "0               0.0          0.0         0.0        0.0              0.0   \n",
       "\n",
       "   brand_Daewoo  brand_Datsun  brand_Fiat  brand_Force  brand_Ford  ...  \\\n",
       "0           0.0           0.0         0.0          0.0         0.0  ...   \n",
       "\n",
       "   brand_Renault  brand_Skoda  brand_Tata  brand_Toyota  brand_Volkswagen  \\\n",
       "0            0.0          0.0         0.0           0.0               0.0   \n",
       "\n",
       "   brand_Volvo  fuel_CNG  fuel_Diesel  fuel_LPG  fuel_Petrol  \n",
       "0          0.0       0.0          0.0       0.0          1.0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 1925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "ohe.fit_transform(X_train)\n",
    "\n",
    "ohe.transform(np.array(['local','Petrol']).reshape(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iM1zg98glu2W",
    "outputId": "f68b2fef-ab29-477e-e9bd-7f1f594656db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[None, 'Petrol']], dtype=object)"
      ]
     },
     "execution_count": 1926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.inverse_transform(np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 1.]).reshape(1,36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGJBUU4hmwUk"
   },
   "source": [
    "### LabelBinarizer\n",
    "\n",
    "- **Purpose**:  \n",
    "  - `LabelBinarizer` is used to **one-hot encode the target (output) feature**.  \n",
    "  - While `LabelEncoder` converts target categories into **single numeric labels** (0, 1, 2, …),  \n",
    "    sometimes we need the output to be **one-hot encoded** instead of a single number.\n",
    "\n",
    "- **When to Use**:\n",
    "  - Useful in **multi-class classification** problems where the model expects  \n",
    "    one-hot encoded targets.\n",
    "  - Examples:\n",
    "    - **Deep learning** models with a `softmax` output layer.\n",
    "    - **Logistic Regression** with a **one-vs-all** strategy.\n",
    "    - Datasets like **Iris**, where the target feature (`species`) has 3 classes.\n",
    "\n",
    "- **Example**:\n",
    "  Suppose the target `y` contains three categories: `['yes', 'no', 'maybe']`.\n",
    "\n",
    "  - Using `LabelEncoder`:\n",
    "    ```\n",
    "    yes → 2\n",
    "    no  → 0\n",
    "    maybe → 1\n",
    "    ```\n",
    "     Only a **single column** with numeric labels.\n",
    "\n",
    "  - Using `LabelBinarizer`:\n",
    "    ```\n",
    "    yes   → [0, 0, 1]\n",
    "    no    → [1, 0, 0]\n",
    "    maybe → [0, 1, 0]\n",
    "    ```\n",
    "     **Three new columns** (`y_no`, `y_maybe`, `y_yes`) representing each class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFSK2YxTmMzC",
    "outputId": "73155445-6af8-4da6-ed68-634c0689d2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized labels:\n",
      " [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Original labels:\n",
      " ['cat' 'dog' 'fish' 'dog' 'cat']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Sample target variable for a multi-class classification problem\n",
    "y = ['cat', 'dog', 'fish', 'dog', 'cat']\n",
    "\n",
    "# Initialize the LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_binarized = lb.fit_transform(y)\n",
    "\n",
    "print(\"Binarized labels:\\n\", y_binarized)\n",
    "\n",
    "# Inverse transform to recover original labels\n",
    "y_original = lb.inverse_transform(y_binarized)\n",
    "\n",
    "print(\"Original labels:\\n\", y_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04b48d56"
   },
   "source": [
    "### MultiLabelBinarizer\n",
    "\n",
    "- **Purpose**:\n",
    "  - Used for **multi-label problems**, where each sample can be associated with **multiple target labels** simultaneously.\n",
    "  - Transforms a list of lists (or similar iterables) of labels into a **binary matrix** where each column corresponds to a unique label and a `1` indicates the presence of that label for a given sample.\n",
    "- **When to Use**:\n",
    "  - When the output column is multi-label. For example, if you have movie summaries and need to identify all applicable genres (a movie can have multiple genres).\n",
    "- **How it Works**:\n",
    "  - It identifies all unique labels across all samples.\n",
    "  - It creates a binary column for each unique label.\n",
    "  - For each sample, it places a `1` in the columns corresponding to the labels present in that sample, and `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "THM5IGhsmzdN",
    "outputId": "107b466f-fdf0-44f6-9c54-4a0ba13801c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary matrix:\n",
      " [[1 0 1]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "Class labels: ['blue' 'green' 'red']\n",
      "Inverse transformed labels: [('blue', 'red'), ('blue', 'green'), ('green',), ('red',)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Example multi-label data\n",
    "y = [('red', 'blue'), ('blue', 'green'), ('green',), ('red',)]\n",
    "\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Fit and transform the data to binary matrix format\n",
    "Y = mlb.fit_transform(y)\n",
    "\n",
    "print(\"Binary matrix:\\n\", Y)\n",
    "print(\"Class labels:\", mlb.classes_)\n",
    "\n",
    "# Inverse transform to recover original labels\n",
    "y_inv = mlb.inverse_transform(Y)\n",
    "print(\"Inverse transformed labels:\", y_inv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4aKN8Z-SfLz"
   },
   "source": [
    "### 3. Count Encoder/Frequency Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Encoding vs Frequency Encoding\n",
    "\n",
    "When working with categorical data in machine learning, we need to convert categories (text labels) into numerical values.  \n",
    "Two common techniques for this are **Count Encoding** and **Frequency Encoding**.  \n",
    "\n",
    "Both techniques aim to represent categorical variables in a numeric form that models can understand, but they differ in *how* they assign values.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Count Encoding \n",
    "\n",
    "### What It Does\n",
    "- Each unique category is replaced by the **number of times** it appears in the dataset.  \n",
    "- This means the encoded value is proportional to how common that category is.  \n",
    "- Categories that appear often will get higher numbers, and rare categories will get smaller numbers.\n",
    "\n",
    "### Why It Helps\n",
    "- Provides a simple way to capture the importance or popularity of a category.  \n",
    "- Keeps categories that occur frequently distinct from those that occur rarely.  \n",
    "- Works well when the absolute number of occurrences matters (e.g., \"most purchased product IDs\").\n",
    "\n",
    "### Example\n",
    "\n",
    "Dataset of pets and their breeds:\n",
    "\n",
    "| Pet ID | Breed     |\n",
    "| :----: | :-------- |\n",
    "|   1    | Labrador  |\n",
    "|   2    | Beagle    |\n",
    "|   3    | Beagle    |\n",
    "|   4    | Labrador  |\n",
    "|   5    | Siamese   |\n",
    "\n",
    "Steps:\n",
    "1. Count occurrences in the `Breed` column:\n",
    "   - Labrador → 2  \n",
    "   - Beagle → 2  \n",
    "   - Siamese → 1  \n",
    "2. Replace each category with its count.\n",
    "\n",
    "**After Count Encoding:**\n",
    "\n",
    "| Pet ID | Breed (Count Encoded) |\n",
    "| :----: | :-------------------- |\n",
    "|   1    | 2                     |\n",
    "|   2    | 2                     |\n",
    "|   3    | 2                     |\n",
    "|   4    | 2                     |\n",
    "|   5    | 1                     |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Frequency Encoding \n",
    "\n",
    "### What It Does\n",
    "- Each unique category is replaced by the **relative frequency** of that category.  \n",
    "- Relative frequency = (Count of category ÷ Total number of rows).  \n",
    "- Values are between `0` and `1`, making the encoding normalized.  \n",
    "\n",
    "### Why It Helps\n",
    "- Useful when dataset sizes differ, since it scales values automatically.  \n",
    "- Prevents raw counts from dominating just because the dataset is large.  \n",
    "- Models can interpret encoded values as probabilities.  \n",
    "\n",
    "### Example\n",
    "\n",
    "Using the same dataset:\n",
    "\n",
    "Total rows = 5  \n",
    "\n",
    "- Labrador → 2/5 = **0.4**  \n",
    "- Beagle → 2/5 = **0.4**  \n",
    "- Siamese → 1/5 = **0.2**\n",
    "\n",
    "**After Frequency Encoding:**\n",
    "\n",
    "| Pet ID | Breed (Frequency Encoded) |\n",
    "| :----: | :------------------------ |\n",
    "|   1    | 0.4                       |\n",
    "|   2    | 0.4                       |\n",
    "|   3    | 0.4                       |\n",
    "|   4    | 0.4                       |\n",
    "|   5    | 0.2                       |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Relationship Between Count and Frequency Encoding \n",
    "\n",
    "At their core, both techniques use the **same idea**:  \n",
    "> Encode a category based on how often it appears.  \n",
    "\n",
    "The only difference is in the **scale of numbers**:  \n",
    "\n",
    "- Count Encoding → Raw counts (e.g., 2, 1, 5).  \n",
    "- Frequency Encoding → Normalized counts (proportions, e.g., 0.4, 0.2).  \n",
    "\n",
    "This means **Frequency Encoding is essentially a normalized version of Count Encoding**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. The `normalize` Parameter in Count Encoder \n",
    "\n",
    "In libraries like `category_encoders`, the **Count Encoder** has a parameter called `normalize`.  \n",
    "\n",
    "- `normalize=False` (default):  \n",
    "  - Outputs raw counts.  \n",
    "  - Example: Labrador → 2, Beagle → 2, Siamese → 1.  \n",
    "\n",
    "- `normalize=True`:  \n",
    "  - Divides counts by the total number of rows, turning them into frequencies.  \n",
    "  - Example: Labrador → 0.4, Beagle → 0.4, Siamese → 0.2.  \n",
    "  - In this case, the Count Encoder **behaves exactly like a Frequency Encoder**.\n",
    "\n",
    "In other words:  \n",
    "`CountEncoder(normalize=True)` = **Frequency Encoder**\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Practical Considerations \n",
    "\n",
    "- **Scaling of Values**  \n",
    "  - Count Encoding → Values can get very large in big datasets.  \n",
    "  - Frequency Encoding → Always between 0 and 1, making it stable across dataset sizes.  \n",
    "\n",
    "- **Interpretability**  \n",
    "  - Count Encoding → Easy to interpret (\"how many times did this category occur?\").  \n",
    "  - Frequency Encoding → Easy to compare across datasets (\"what proportion of the dataset is this category?\").  \n",
    "\n",
    "- **Model Sensitivity**  \n",
    "  - Tree-based models (like Random Forest, XGBoost) are usually fine with either encoding.  \n",
    "  - Linear models may prefer Frequency Encoding since values are normalized and won’t distort scale.\n",
    "\n",
    "---\n",
    "\n",
    "- **Count Encoding** → Categories replaced by raw counts.  \n",
    "- **Frequency Encoding** → Categories replaced by relative frequencies.  \n",
    "- **`normalize=True` in Count Encoder** → Makes it act like Frequency Encoding.  \n",
    "\n",
    "Both methods are powerful, and the choice depends on whether you care about **absolute counts** or **relative proportions** in your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tpWdMkWVSseW",
    "outputId": "c6d20b34-4bd0-4545-d629-1581efc84ff3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>State</th>\n",
       "      <th>Education</th>\n",
       "      <th>Package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>PG</td>\n",
       "      <td>17.465839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>High School</td>\n",
       "      <td>32.798800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>High School</td>\n",
       "      <td>68.034867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>UG</td>\n",
       "      <td>6.320762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>High School</td>\n",
       "      <td>60.724937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age        State    Education    Package\n",
       "0  38.0   Tamil Nadu           PG  17.465839\n",
       "1  27.0  Maharashtra  High School  32.798800\n",
       "2   NaN    Telangana  High School  68.034867\n",
       "3  21.0        Delhi           UG   6.320762\n",
       "4  22.0    Karnataka  High School  60.724937"
      ]
     },
     "execution_count": 1929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset generation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "# Simulating a dataset\n",
    "data = {\n",
    "    'Age': np.random.randint(20, 60, size=100).astype(float),  # Random ages between 20 and 60\n",
    "    'State': np.random.choice(['Karnataka', 'Tamil Nadu', 'Maharashtra', 'Delhi', 'Telangana'], size=100),\n",
    "    'Education': np.random.choice(['High School', 'UG', 'PG'], size=100),\n",
    "    'Package': np.random.rand(100) * 100  # Random package values for demonstration\n",
    "}\n",
    "\n",
    "# Introducing missing values in 'Age' column (5%)\n",
    "np.random.seed(0)  # For reproducibility\n",
    "missing_indices = np.random.choice(data['Age'].shape[0], replace=False, size=int(data['Age'].shape[0] * 0.05))\n",
    "data['Age'][missing_indices] = np.nan\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {
    "id": "AkUd7R7YXxJR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['Package']), df['Package'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2RvTw_etFGch",
    "outputId": "6ace2565-715b-4b5d-93c2-6988afb8c569"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>State</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>34.0</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age        State    Education\n",
       "55   NaN   Tamil Nadu  High School\n",
       "88  34.0  Maharashtra           UG\n",
       "26   NaN  Maharashtra  High School\n",
       "42  25.0    Karnataka           UG\n",
       "69  30.0        Delhi           PG"
      ]
     },
     "execution_count": 1931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "Y4ja7xCYE6Q1",
    "outputId": "78d540a5-9072-4834-b0c7-7a1cf3b3bf37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "Maharashtra    25\n",
       "Telangana      18\n",
       "Delhi          15\n",
       "Tamil Nadu     12\n",
       "Karnataka      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {
    "id": "Vo2sR_JLWLaQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {
    "id": "A3_5NP6wXaYs"
   },
   "outputs": [],
   "source": [
    "class CountEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.count_map = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.columns is None:\n",
    "            self.columns = X.columns\n",
    "        for col in self.columns:\n",
    "            self.count_map[col] = X[col].value_counts().to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            X[col] = X[col].map(self.count_map[col]).fillna(0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {
    "id": "Fc1Ti-J4Ws1i"
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('age_missing', SimpleImputer(strategy='mean'), ['Age']),\n",
    "        ('cat_state', CountEncoder(), ['State']),\n",
    "        ('education_ordinal', OrdinalEncoder(), ['Education'])\n",
    "    ])\n",
    "\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "hThTmIrUXulG",
    "outputId": "b8d1b56f-2c5d-4e5b-d08c-ece939f782d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_missing__Age</th>\n",
       "      <th>cat_state__State</th>\n",
       "      <th>education_ordinal__Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>37.586667</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37.586667</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_missing__Age  cat_state__State  education_ordinal__Education\n",
       "55         37.586667                12                           0.0\n",
       "88         34.000000                25                           2.0\n",
       "26         37.586667                25                           0.0\n",
       "42         25.000000                10                           2.0\n",
       "69         30.000000                15                           1.0\n",
       "..               ...               ...                           ...\n",
       "60         26.000000                10                           0.0\n",
       "71         45.000000                15                           0.0\n",
       "14         32.000000                25                           0.0\n",
       "92         49.000000                25                           0.0\n",
       "51         45.000000                18                           2.0\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 1936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using category encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {
    "id": "THmohRgZYLgo"
   },
   "outputs": [],
   "source": [
    "from category_encoders.count import CountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('age_missing', SimpleImputer(strategy='mean'), ['Age']),\n",
    "        ('cat_state', CountEncoder(), ['State']),\n",
    "        ('education_ordinal', OrdinalEncoder(), ['Education'])\n",
    "    ])\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_missing__Age</th>\n",
       "      <th>cat_state__State</th>\n",
       "      <th>education_ordinal__Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>37.586667</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37.586667</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_missing__Age  cat_state__State  education_ordinal__Education\n",
       "55         37.586667                12                           0.0\n",
       "88         34.000000                25                           2.0\n",
       "26         37.586667                25                           0.0\n",
       "42         25.000000                10                           2.0\n",
       "69         30.000000                15                           1.0\n",
       "..               ...               ...                           ...\n",
       "60         26.000000                10                           0.0\n",
       "71         45.000000                15                           0.0\n",
       "14         32.000000                25                           0.0\n",
       "92         49.000000                25                           0.0\n",
       "51         45.000000                18                           2.0\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 1939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "metadata": {
    "id": "Ar8YLo04Y1j4"
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('age_missing', SimpleImputer(strategy='mean'), ['Age']),\n",
    "        ('cat_state', CountEncoder(normalize=True), ['State']),\n",
    "        ('education_ordinal', OrdinalEncoder(), ['Education'])\n",
    "    ])\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "XVIt9eHoY7NN",
    "outputId": "3ad8ff32-b700-491f-c6c1-7003b1e708f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_missing__Age</th>\n",
       "      <th>cat_state__State</th>\n",
       "      <th>education_ordinal__Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>37.586667</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>37.586667</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_missing__Age  cat_state__State  education_ordinal__Education\n",
       "55         37.586667            0.1500                           0.0\n",
       "88         34.000000            0.3125                           2.0\n",
       "26         37.586667            0.3125                           0.0\n",
       "42         25.000000            0.1250                           2.0\n",
       "69         30.000000            0.1875                           1.0\n",
       "..               ...               ...                           ...\n",
       "60         26.000000            0.1250                           0.0\n",
       "71         45.000000            0.1875                           0.0\n",
       "14         32.000000            0.3125                           0.0\n",
       "92         49.000000            0.3125                           0.0\n",
       "51         45.000000            0.2250                           2.0\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 1941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>High School</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          State    Education\n",
       "0         Delhi           PG\n",
       "1     Telangana  High School\n",
       "2   Maharashtra  High School\n",
       "3     Telangana  High School\n",
       "4     Telangana           PG\n",
       "5    Tamil Nadu  High School\n",
       "6   Maharashtra          NaN\n",
       "7   Maharashtra  High School\n",
       "8   Maharashtra          NaN\n",
       "9     Telangana          NaN\n",
       "10        Delhi          NaN\n",
       "11  Maharashtra           PG\n",
       "12          NaN           PG\n",
       "13    Telangana           PG\n",
       "14   Tamil Nadu  High School\n",
       "15        Delhi          NaN\n",
       "16          NaN           PG\n",
       "17          NaN           PG\n",
       "18   Tamil Nadu  High School\n",
       "19        Delhi           PG\n",
       "20    Telangana  High School\n",
       "21    Karnataka           UG\n",
       "22        Delhi           PG\n",
       "23   Tamil Nadu           UG\n",
       "24          NaN  High School"
      ]
     },
     "execution_count": 1942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "# Simulating a dataset\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "data = {\n",
    "    'State': np.random.choice(\n",
    "        ['Karnataka', 'Tamil Nadu', 'Maharashtra', 'Delhi', 'Telangana', np.nan],\n",
    "        size=100\n",
    "    ),\n",
    "    'Education': np.random.choice(\n",
    "        ['High School', 'UG', 'PG', np.nan],\n",
    "        size=100\n",
    "    )\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.replace(\"nan\", np.nan, inplace=True)\n",
    "\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1943,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "oPTg0sLpJITN",
    "outputId": "981a46e8-68d9-485f-9e4f-749c49bf74eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State        17\n",
       "Education    23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Encoder Parameters: `handle_unknown`, `handle_missing`, `min_group_size`, `min_group_name`, `combine_min_nan_groups`\n",
    "\n",
    "When applying **Count Encoding** using libraries such as `category_encoders`, we have several important parameters that control how categories are grouped and how special cases are handled.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. `handle_unknown`\n",
    "\n",
    "This parameter defines the behavior when the model encounters **unseen categories** (i.e., categories that were not present during training but appear during inference).\n",
    "\n",
    "- **Options:**\n",
    "  - `\"error\"` → Raises an error if an unknown category is found.  \n",
    "  - `\"value\"` → Encodes the unknown category with a specific value (default is often `None`, which gets treated as 0 or another placeholder).  \n",
    "  - `\"return_nan\"` → Returns `NaN` for unknown categories, leaving it for the user to handle later.\n",
    "\n",
    "- **Example:**  \n",
    "  If training data has breeds `{Labrador, Beagle, Siamese}` and test data contains `Pug`, the encoding behavior depends on this parameter.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. `handle_missing`\n",
    "\n",
    "This parameter defines how the encoder deals with **missing values** (`NaN`) in the categorical feature.\n",
    "\n",
    "- **Options:**\n",
    "  - `\"error\"` → Raises an error if missing values are present.  \n",
    "  - `\"value\"` → Encodes missing values with a specific placeholder (e.g., 0).  \n",
    "  - `\"return_nan\"` → Keeps them as `NaN` in the transformed dataset.  \n",
    "\n",
    "- **Example:**  \n",
    "  If the `Breed` column has some missing values, they will be encoded differently depending on this setting.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. `min_group_size`\n",
    "\n",
    "This parameter sets a **minimum threshold** for how many times a category must appear in the dataset.  \n",
    "\n",
    "- If a category occurs fewer times than `min_group_size`, it will not be encoded separately.  \n",
    "- Instead, such rare categories are grouped together under a single label (defined by `min_group_name`).  \n",
    "\n",
    "**Why it’s useful:**  \n",
    "- Prevents overfitting on categories that occur very rarely.  \n",
    "- Ensures that categories with too few samples don’t produce unstable encodings.  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. `min_group_name`\n",
    "\n",
    "When categories are combined due to `min_group_size`, this parameter specifies the **name of the new grouped category**.  \n",
    "\n",
    "- Common values: `\"__other__\"`, `\"rare\"`, or any custom string you provide.  \n",
    "- All categories below the frequency threshold will be merged under this name before encoding.  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. `combine_min_nan_groups`\n",
    "\n",
    "This parameter controls whether **rare categories (below `min_group_size`)** should be grouped together **with missing values (`NaN`)**.  \n",
    "\n",
    "- `True` → Missing values and rare categories are combined into the same group.  \n",
    "- `False` → Missing values are handled separately from rare categories.  \n",
    "\n",
    "**Why it matters:**  \n",
    "- If your dataset has both rare categories and many missing values, combining them can simplify the feature space.  \n",
    "- But if you want to treat missing values differently from rare categories, keep this set to `False`.\n",
    "\n",
    "---\n",
    "\n",
    "##  Why These Parameters Matter\n",
    "\n",
    "- **`handle_unknown` / `handle_missing`** → Deal with unseen or missing data.  \n",
    "- **`min_group_size` / `min_group_name` / `combine_min_nan_groups`** → Control how rare categories and missing values are grouped.  \n",
    "\n",
    "Together, these parameters give you fine-grained control over how categorical data is transformed, making your encodings more **robust**, **consistent**, and **production-ready**.\n",
    "\n",
    "---\n",
    "\n",
    "**Best Practice Tip**:  \n",
    "- Use `min_group_size` to avoid overfitting on rare categories.  \n",
    "- Set a clear `min_group_name` (e.g., `\"rare\"`) for transparency.  \n",
    "- Only use `combine_min_nan_groups=True` if it makes sense to merge missing values with rare categories in your context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {
    "id": "8ZyOqnPBnaOl"
   },
   "outputs": [],
   "source": [
    "# Initialize the CountEncoder with various parameters\n",
    "encoder = ce.CountEncoder(\n",
    "    cols=['State', 'Education'],  # Specify columns to encode. None would automatically select categorical columns.\n",
    "    handle_missing='value',  # Treat NaNs as a countable category\n",
    "    handle_unknown='value',  # Treat unknown categories as NaNs (if seen during transform but not in fit)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "UY8hq0GJncQW",
    "outputId": "cddf316f-192d-4208-f1e3-ebbd33a40244"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State  Education\n",
       "0      25         34\n",
       "1      17         27\n",
       "2      11         27\n",
       "3      17         27\n",
       "4      17         34\n",
       "..    ...        ...\n",
       "95     25         27\n",
       "96     25         16\n",
       "97     17         23\n",
       "98     11         23\n",
       "99     17         23\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 1945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the dataset\n",
    "encoder.fit_transform(df)\n",
    "\n",
    "#print(encoded_df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLK_RwgXnhHZ",
    "outputId": "03785564-c1e0-48b1-b340-b553aa2a4500"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'State': State\n",
       " Delhi          25\n",
       " Tamil Nadu     19\n",
       " Telangana      17\n",
       " NaN            17\n",
       " Maharashtra    11\n",
       " Karnataka      11\n",
       " Name: count, dtype: int64,\n",
       " 'Education': Education\n",
       " PG             34\n",
       " High School    27\n",
       " NaN            23\n",
       " UG             16\n",
       " Name: count, dtype: int64}"
      ]
     },
     "execution_count": 1946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "FUJDEICMquiA",
    "outputId": "dcc6c89c-b79d-4b4a-b8c6-ec24fe7a9810"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  Education\n",
       "0    0.0         16"
      ]
     },
     "execution_count": 1947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.DataFrame({'State': ['Bihar'], 'Education': ['UG']})\n",
    "\n",
    "encoder.transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "qUbUb3yDrdLh",
    "outputId": "c77a96f8-fd6f-497d-cef1-e31c34432c9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>C</td>\n",
       "      <td>0.209844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>B</td>\n",
       "      <td>0.290078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.735194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>C</td>\n",
       "      <td>0.149448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>C</td>\n",
       "      <td>0.806194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>A</td>\n",
       "      <td>0.704414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>C</td>\n",
       "      <td>0.298282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>B</td>\n",
       "      <td>0.855803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>A</td>\n",
       "      <td>0.223925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>C</td>\n",
       "      <td>0.703889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category     Value\n",
       "91        C  0.209844\n",
       "29        B  0.290078\n",
       "2         C  0.735194\n",
       "50        C  0.149448\n",
       "44        C  0.806194\n",
       "78        A  0.704414\n",
       "33        C  0.298282\n",
       "65        B  0.855803\n",
       "75        A  0.223925\n",
       "45        C  0.703889"
      ]
     },
     "execution_count": 1948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)  # For reproducibility\n",
    "data = {\n",
    "    'Category': np.random.choice(['A', 'B', 'C', 'D', 'E', 'F', np.nan], size=100, p=[0.3, 0.25, 0.15, 0.15, 0.05, 0.05, 0.05]),\n",
    "    'Value': np.random.rand(100)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "dqgaxZfWDFmE",
    "outputId": "07c3e740-0cd1-44dd-fc17-b86cb18c6424"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "A      34\n",
       "B      22\n",
       "C      21\n",
       "D      12\n",
       "nan     5\n",
       "F       4\n",
       "E       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "metadata": {
    "id": "J329mSRRCYBw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category     Value  Encoded\n",
      "0         B  0.677817       22\n",
      "1         D  0.270008       12\n",
      "2         C  0.735194       21\n",
      "3         B  0.962189       22\n",
      "4         B  0.248753       22\n",
      "5         C  0.576157       21\n",
      "6         B  0.592042       22\n",
      "7         E  0.572252        6\n",
      "8       nan  0.223082        5\n",
      "9         B  0.952749       22\n",
      "10        D  0.447125       12\n",
      "11        B  0.846409       22\n",
      "12        C  0.699479       21\n",
      "13        F  0.297437        6\n",
      "14        A  0.813798       34\n",
      "15        A  0.396506       34\n",
      "16        A  0.881103       34\n",
      "17        D  0.581273       12\n",
      "18        D  0.881735       12\n",
      "19        E  0.692532        6\n"
     ]
    }
   ],
   "source": [
    "encoder = ce.CountEncoder(\n",
    "    cols=['Category'],\n",
    "    min_group_size=5,  # Groups with counts less than 5 will be combined\n",
    "    min_group_name='others',  # Use default naming for combined minimum groups\n",
    ")\n",
    "\n",
    "# Fit and transform the dataset\n",
    "encoded_df = encoder.fit_transform(df['Category'])\n",
    "\n",
    "# Display the original and encoded data for comparison\n",
    "df['Encoded'] = encoded_df\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "metadata": {
    "id": "o29K_XhFDA0r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Category': Category\n",
       " A         34\n",
       " B         22\n",
       " C         21\n",
       " D         12\n",
       " nan        5\n",
       " others     6\n",
       " Name: count, dtype: int64}"
      ]
     },
     "execution_count": 1951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5A0dJdcHt3z"
   },
   "source": [
    "# Binary Encoding\n",
    "\n",
    "Binary Encoding is a technique used for converting categorical data into numerical format for machine learning models.  \n",
    "\n",
    "Unlike **One-Hot Encoding**:\n",
    "- One-hot creates a new column for every unique category (which can lead to very high dimensionality if categories are many).\n",
    "- Binary Encoding reduces dimensionality by first converting categories into integers, then representing those integers in **binary form**, and finally splitting the binary digits across multiple columns.\n",
    "\n",
    "---\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. Assign an **integer value** to each category.  \n",
    "2. Convert these integer values into **binary numbers**.  \n",
    "3. Split the binary digits into separate columns (bits).  \n",
    "\n",
    "This way, fewer columns are created compared to one-hot encoding.\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Consider a dataset of fruits:\n",
    "\n",
    "### Original Dataset\n",
    "\n",
    "| Item  | Fruit      |\n",
    "|-------|-----------|\n",
    "| Item1 | Apple     |\n",
    "| Item2 | Banana    |\n",
    "| Item3 | Cherry    |\n",
    "| Item4 | Date      |\n",
    "| Item5 | Elderberry|\n",
    "| Item6 | Fig       |\n",
    "| Item7 | Grape     |\n",
    "| Item8 | Honeydew  |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Assign Integers\n",
    "\n",
    "| Fruit      | Integer |\n",
    "|------------|---------|\n",
    "| Apple      | 1       |\n",
    "| Banana     | 2       |\n",
    "| Cherry     | 3       |\n",
    "| Date       | 4       |\n",
    "| Elderberry | 5       |\n",
    "| Fig        | 6       |\n",
    "| Grape      | 7       |\n",
    "| Honeydew   | 8       |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Convert Integers → Binary\n",
    "\n",
    "- 1 → `0001`  \n",
    "- 2 → `0010`  \n",
    "- 3 → `0011`  \n",
    "- 4 → `0100`  \n",
    "- 5 → `0101`  \n",
    "- 6 → `0110`  \n",
    "- 7 → `0111`  \n",
    "- 8 → `1000`  \n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Split Binary into Columns\n",
    "\n",
    "| Item  | Fruit      | Bit1 | Bit2 | Bit3 | Bit4 |\n",
    "|-------|-----------|------|------|------|------|\n",
    "| Item1 | Apple     | 0    | 0    | 0    | 1    |\n",
    "| Item2 | Banana    | 0    | 0    | 1    | 0    |\n",
    "| Item3 | Cherry    | 0    | 0    | 1    | 1    |\n",
    "| Item4 | Date      | 0    | 1    | 0    | 0    |\n",
    "| Item5 | Elderberry| 0    | 1    | 0    | 1    |\n",
    "| Item6 | Fig       | 0    | 1    | 1    | 0    |\n",
    "| Item7 | Grape     | 0    | 1    | 1    | 1    |\n",
    "| Item8 | Honeydew  | 1    | 0    | 0    | 0    |\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages \n",
    "- **Reduces dimensionality** compared to One-Hot Encoding.  \n",
    "- Works well with **high-cardinality categorical features**.  \n",
    "- Keeps some **ordinal relationship** through binary digits.  \n",
    "\n",
    "## Disadvantages \n",
    "- Slightly more complex than One-Hot or Label Encoding.  \n",
    "- Models may **misinterpret binary patterns** as having ordinal meaning.  \n",
    "- Not as interpretable as One-Hot.  \n",
    "\n",
    "---\n",
    "\n",
    "## Practical Use Cases\n",
    "- Large datasets with **high-cardinality categorical variables** (e.g., user IDs, product codes, zip codes).  \n",
    "- Works well with **tree-based models** (Random Forest, XGBoost, LightGBM).  \n",
    "- Useful when **memory and computation cost** are important concerns.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "metadata": {
    "id": "2JYLIF0lDey7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Fruit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Item1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Item2</td>\n",
       "      <td>Banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Item3</td>\n",
       "      <td>Cherry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Item4</td>\n",
       "      <td>Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Item5</td>\n",
       "      <td>Elderberry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Item6</td>\n",
       "      <td>Fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Item7</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Item8</td>\n",
       "      <td>Honeydew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Item       Fruit\n",
       "0  Item1       Apple\n",
       "1  Item2      Banana\n",
       "2  Item3      Cherry\n",
       "3  Item4        Date\n",
       "4  Item5  Elderberry\n",
       "5  Item6         Fig\n",
       "6  Item7       Grape\n",
       "7  Item8    Honeydew"
      ]
     },
     "execution_count": 1952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Item': ['Item1', 'Item2', 'Item3', 'Item4', 'Item5', 'Item6', 'Item7', 'Item8'],\n",
    "    'Fruit': ['Apple', 'Banana', 'Cherry', 'Date', 'Elderberry', 'Fig', 'Grape', 'Honeydew']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1953,
   "metadata": {
    "id": "MpDmdiDzKw5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Item  Fruit_0  Fruit_1  Fruit_2  Fruit_3\n",
      "0  Item1        0        0        0        1\n",
      "1  Item2        0        0        1        0\n",
      "2  Item3        0        0        1        1\n",
      "3  Item4        0        1        0        0\n",
      "4  Item5        0        1        0        1\n",
      "5  Item6        0        1        1        0\n",
      "6  Item7        0        1        1        1\n",
      "7  Item8        1        0        0        0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Binary Encoder\n",
    "encoder = ce.BinaryEncoder(cols=['Fruit'], return_df=True)\n",
    "\n",
    "# Fit and transform the data\n",
    "df_encoded = encoder.fit_transform(df)\n",
    "\n",
    "# Display the original and encoded data\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TJ7g103LT-c"
   },
   "source": [
    "### Target Encoder/mean encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1954,
   "metadata": {
    "id": "iZHeT2zEK4hZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Target   Feature\n",
      "0        A       1  0.631436\n",
      "1        B       0  0.579948\n",
      "2        A       0  0.631436\n",
      "3        B       1  0.579948\n",
      "4        C       1  0.678194\n",
      "5        A       1  0.631436\n",
      "6        B       0  0.579948\n",
      "7        C       1  0.678194\n"
     ]
    }
   ],
   "source": [
    "# using category_encoder\n",
    "\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Feature': ['A', 'B', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'Target': [1, 0, 0, 1, 1, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separating the feature and target columns\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Initialize the TargetEncoder\n",
    "encoder = ce.TargetEncoder(cols=['Feature'])\n",
    "\n",
    "# Fit the encoder using the feature data and target variable\n",
    "encoder.fit(X, y)\n",
    "\n",
    "# Transform the data\n",
    "encoded = encoder.transform(X)\n",
    "\n",
    "# Show the original and encoded data\n",
    "print(pd.concat([df, encoded], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1955,
   "metadata": {
    "id": "_v_rGQRdoYqK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Feature': Feature\n",
       "  1    0.631436\n",
       "  2    0.579948\n",
       "  3    0.678194\n",
       " -1    0.625000\n",
       " -2    0.625000\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 1955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "wO7KviwTLWlU",
    "outputId": "aa73823c-724a-4ebd-af5b-288d71bd9ebf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature\n",
       "0  0.666667\n",
       "1  0.333333\n",
       "2  0.666667\n",
       "3  0.333333\n",
       "4  1.000000\n",
       "5  0.666667\n",
       "6  0.333333\n",
       "7  1.000000"
      ]
     },
     "execution_count": 1956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'Feature': ['A', 'B', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'Target': [1, 0, 0, 1, 1, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Separating the feature and target columns\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Initialize the TargetEncoder\n",
    "encoder = TargetEncoder(smooth=0.0)\n",
    "\n",
    "# Fit the encoder using the feature data and target variable\n",
    "encoder.fit(X, y)\n",
    "\n",
    "# Transform the data\n",
    "encoded = encoder.transform(X)\n",
    "\n",
    "encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqgYGRh4ts7w"
   },
   "source": [
    "# Weight of Evidence (WoE) Encoding\n",
    "\n",
    "**Weight of Evidence (WoE)** is a powerful technique used primarily in **credit risk modeling** and other areas of **financial analytics**, but its utility extends to any predictive modeling task that involves categorical variables.  \n",
    "\n",
    "WoE encoding transforms categorical variables into a **continuous scale**, representing the logarithmic ratio of the distribution of *\"good\"* outcomes to the distribution of *\"bad\"* outcomes within each category.  \n",
    "This makes WoE particularly useful for **binary classification problems**.\n",
    "\n",
    "---\n",
    "\n",
    "## Formula for Weight of Evidence\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{WoE} = \\ln \\left( \\frac{\\text{Distribution of Good}}{\\text{Distribution of Bad}} \\right)\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "\n",
    "- **Distribution of Good** → Proportion of *positive* outcomes within the category  \n",
    "- **Distribution of Bad** → Proportion of *negative* outcomes within the category  \n",
    "- **ln** → Natural logarithm  \n",
    "\n",
    "---\n",
    "\n",
    "In practice, WoE helps in:  \n",
    "- Capturing the predictive power of categorical variables  \n",
    "- Handling variables with strong separation between classes  \n",
    "- Making features more interpretable in models such as **Logistic Regression**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WoE Encoding: A Practical Example \n",
    "\n",
    "Following the theory, let's walk through a practical example of calculating the **Weight of Evidence (WoE)**. We will encode the `EmploymentStatus` categorical feature based on its relationship with the `LoanOutcome` target variable.\n",
    "\n",
    "**Our Goal:** Convert the categories 'Employed', 'Unemployed', and 'Student' into meaningful numerical WoE scores.\n",
    "\n",
    "**Initial Dataset:**\n",
    "| ApplicationID | EmploymentStatus | LoanOutcome |\n",
    "|:-------------:|:----------------:|:-----------:|\n",
    "| 1             | Employed         | Good        |\n",
    "| 2             | Unemployed       | Bad         |\n",
    "| 3             | Employed         | Bad         |\n",
    "| 4             | Student          | Good        |\n",
    "| 5             | Employed         | Good        |\n",
    "| 6             | Unemployed       | Bad         |\n",
    "| 7             | Student          | Bad         |\n",
    "| 8             | Employed         | Good        |\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 1: Calculate Frequency of Good and Bad Outcomes\n",
    "\n",
    "First, we group by each category in `EmploymentStatus` and count the number of \"Good\" (event) and \"Bad\" (non-event) outcomes.\n",
    "\n",
    "| EmploymentStatus | Good | Bad |\n",
    "|:-----------------|:----:|:---:|\n",
    "| Employed         | 3    | 1   |\n",
    "| Unemployed       | **0**| 2   |\n",
    "| Student          | 1    | 1   |\n",
    "| **Total** | **4**| **4**|\n",
    "\n",
    "Here, we notice the **\"Unemployed\"** category has zero \"Good\" outcomes, which requires special handling.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Calculate the Distribution of Good and Bad\n",
    "\n",
    "Next, we find the proportion of all \"Good\" and \"Bad\" outcomes that belong to each category.\n",
    "\n",
    "* **Distribution of Good** = (Count of 'Good' in Category) / (Total 'Good')\n",
    "* **Distribution of Bad** = (Count of 'Bad' in Category) / (Total 'Bad')\n",
    "\n",
    "| EmploymentStatus | Distribution of Good | Distribution of Bad |\n",
    "|:-----------------|:--------------------:|:-------------------:|\n",
    "| Employed         | 3 / 4 = **0.75** | 1 / 4 = **0.25** |\n",
    "| Unemployed       | 0 / 4 = **0.00** | 2 / 4 = **0.50** |\n",
    "| Student          | 1 / 4 = **0.25** | 1 / 4 = **0.25** |\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Apply the WoE Formula & Handle Division by Zero\n",
    "\n",
    "The WoE is the natural logarithm of the ratio of these distributions.\n",
    "\n",
    "$$\n",
    "\\text{WoE} = \\ln \\left( \\frac{\\text{Distribution of Good}}{\\text{Distribution of Bad}} \\right)\n",
    "$$\n",
    "\n",
    "For the \"Unemployed\" category, the calculation `ln(0.00 / 0.50)` results in `ln(0)`, which is mathematically undefined.\n",
    "\n",
    "To solve this, we adjust the original count of `0` to a very small number (e.g., `0.001`) to prevent this error.\n",
    "\n",
    "**Adjusted Counts:**\n",
    "* **Good outcomes for \"Unemployed\"**: `0.001`\n",
    "* **New Total Good outcomes**: `3 + 1 + 0.001 = 4.001`\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4: Recalculate Distributions and Final WoE Scores\n",
    "\n",
    "Using the adjusted total, we re-calculate the WoE for all categories to ensure consistency.\n",
    "\n",
    "| EmploymentStatus | Calculation                                | Final WoE |\n",
    "|:-----------------|:-------------------------------------------|:---------:|\n",
    "| Employed         | $\\ln \\left( (3/4.001) / (1/4) \\right)$     | **+1.098**|\n",
    "| Unemployed       | $\\ln \\left( (0.001/4.001) / (2/4) \\right)$ | **-7.601**|\n",
    "| Student          | $\\ln \\left( (1/4.001) / (1/4) \\right)$     | **0.000** |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 5: Final Encoded Table and Interpretation \n",
    "\n",
    "The final step is to map these WoE scores back to the original categories. This new numerical feature is now ready for modeling.\n",
    "\n",
    "| EmploymentStatus | Final WoE | Risk Interpretation     |\n",
    "|:-----------------|:---------:|:------------------------|\n",
    "| Employed         | +1.098    | **Lower Risk** |\n",
    "| Unemployed       | -7.601    | **Very High Risk** |\n",
    "| Student          | 0.000     | **Neutral / No Insight**|\n",
    "\n",
    "Final Encoded Dataset\n",
    "\n",
    "Now, replacing `EmploymentStatus` with WoE scores:\n",
    "\n",
    "| ApplicationID | EmploymentStatus (WoE) | LoanOutcome |\n",
    "|:-------------:|:----------------------:|:-----------:|\n",
    "| 1             | +1.098                 | Good        |\n",
    "| 2             | -7.601                 | Bad         |\n",
    "| 3             | +1.098                 | Bad         |\n",
    "| 4             | 0.000                  | Good        |\n",
    "| 5             | +1.098                 | Good        |\n",
    "| 6             | -7.601                 | Bad         |\n",
    "| 7             | 0.000                  | Bad         |\n",
    "| 8             | +1.098                 | Good        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Monotonic Relationship in Weight of Evidence (WoE)\n",
    "\n",
    "One of the **biggest advantages** of **WoE encoding** is that it creates (or enforces) a **monotonic relationship** between the encoded feature and the **target variable** (usually \"Good\" vs. \"Bad\").  \n",
    "\n",
    "---\n",
    "\n",
    "####  What does monotonic mean here?\n",
    "\n",
    "A **monotonic relationship** means that as the **WoE value increases**, the probability of the target being \"Good\" (or \"Bad\") moves in **one consistent direction** — it either always increases or always decreases, but never switches back and forth.\n",
    "\n",
    "- If **WoE increases → Probability of Good increases** (positive monotonicity).  \n",
    "- If **WoE decreases → Probability of Good decreases** (negative monotonicity).  \n",
    "\n",
    "This ensures that the model learns a **clean, ordered relationship** between categories and the outcome.\n",
    "\n",
    "---\n",
    "\n",
    "####  Example (from our dataset)\n",
    "\n",
    "Final WoE scores for `EmploymentStatus`:\n",
    "\n",
    "| EmploymentStatus | Final WoE | Interpretation     |\n",
    "|------------------|-----------|--------------------|\n",
    "| Employed         | +1.098    | Lower Risk (more Good) |\n",
    "| Student          | 0.000     | Neutral            |\n",
    "| Unemployed       | -7.601    | Very High Risk (more Bad) |\n",
    "\n",
    "We can observe the monotonic pattern:\n",
    "\n",
    "- **Unemployed (-7.601)** → Strongly associated with **Bad** outcomes.  \n",
    "- **Student (0.000)** → Balanced / neutral.  \n",
    "- **Employed (+1.098)** → Strongly associated with **Good** outcomes.  \n",
    "\n",
    "As WoE **increases from -7.601 → 0.000 → +1.098**, the likelihood of \"Good\" outcomes also **increases monotonically**.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Why is this useful?\n",
    "\n",
    "1. **Model Stability**: Logistic regression and credit risk models prefer features that have a **linear / monotonic relationship** with the log-odds of the target. WoE encoding directly provides this.  \n",
    "2. **Interpretability**: You can interpret categories in terms of risk. A higher WoE always means \"less risky\" (or more Good), which makes sense to domain experts.  \n",
    "3. **Avoids Overfitting**: Unlike one-hot encoding, WoE summarizes categories into an ordered numeric scale, reducing model complexity.  \n",
    "\n",
    "---\n",
    "\n",
    " **In simple terms:**  \n",
    "WoE transforms messy categories into numbers that line up nicely with the target variable, so the model sees a clean \"increasing or decreasing\" pattern.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Advantages\n",
    "1. **Monotonic Relationship**  \n",
    "   - Ensures a clear, ordered relationship between categories and the target variable.  \n",
    "   - Very useful for logistic regression and credit risk models.  \n",
    "\n",
    "2. **Interpretability**  \n",
    "   - Easy to explain to domain experts (e.g., higher WoE = lower risk).  \n",
    "   - Values directly relate to \"risk\" or \"likelihood\" of an event.  \n",
    "\n",
    "3. **Handles Categorical Variables Well**  \n",
    "   - Converts categories into continuous numeric values, reducing dimensionality compared to one-hot encoding.  \n",
    "\n",
    "4. **Stability**  \n",
    "   - More stable than raw categories when applied to datasets with many categories.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Disadvantages\n",
    "1. **Requires a Binary Target**  \n",
    "   - Works best only in **binary classification problems** (e.g., Good vs. Bad).  \n",
    "   - Not directly suitable for regression or multi-class classification.  \n",
    "\n",
    "2. **Dependent on Target Information**  \n",
    "   - WoE uses the target variable for encoding, so it must be applied **after train-test split** to avoid data leakage.  \n",
    "\n",
    "3. **Handling of Zero Frequencies**  \n",
    "   - If a category has **0 Good or 0 Bad outcomes**, WoE becomes undefined (`ln(0)` issue).  \n",
    "   - Requires smoothing (e.g., replacing 0 with 0.001).  \n",
    "\n",
    "4. **Not Always Generalizable**  \n",
    "   - WoE encoding may overfit if calculated on small datasets or categories with very few observations.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Use Cases\n",
    "1. **Credit Risk Modeling**  \n",
    "   - Widely used in banking to score customers (Good = repays loan, Bad = defaults).  \n",
    "\n",
    "2. **Fraud Detection**  \n",
    "   - Helps quantify the likelihood of fraud based on categorical attributes.  \n",
    "\n",
    "3. **Insurance Risk Assessment**  \n",
    "   - Used to assess customer claim risks based on categorical factors (e.g., job type, region).  \n",
    "\n",
    "4. **Any Binary Classification Task**  \n",
    "   - When interpretability and monotonic relationships are desired.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ph3u11nFMCfO",
    "outputId": "6f413511-62ea-4a4c-f760-3f68ff2d444e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Target  Feature_Encoded\n",
      "0       A       1         0.000000\n",
      "1       B       0        -0.405465\n",
      "2       A       0         0.000000\n",
      "3       C       1         0.405465\n",
      "4       B       1        -0.405465\n",
      "5       A       0         0.000000\n",
      "6       C       1         0.405465\n",
      "7       B       0        -0.405465\n",
      "8       A       1         0.000000\n",
      "9       C       0         0.405465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'Feature': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
    "    'Target': [1, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the features and target\n",
    "X = df[['Feature']]\n",
    "y = df['Target']\n",
    "\n",
    "# Initialize and fit the TargetEncoder\n",
    "encoder = ce.WOEEncoder(cols=['Feature'])\n",
    "X_encoded = encoder.fit_transform(X, y)\n",
    "\n",
    "# Display the original and encoded data\n",
    "df['Feature_Encoded'] = X_encoded\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmP4GQQatweu"
   },
   "source": [
    "### Choosing the Right Categorical Encoding\n",
    "\n",
    "---\n",
    "\n",
    "####  One-Hot Encoder (OHE)\n",
    " \n",
    "- Best for **low cardinality features** (few unique categories).  \n",
    "- Ideal in **linear models** and **neural networks**, where preserving category distinction without implying order is crucial.  \n",
    "-  Beware of **dimensionality explosion** if categories are many.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Ordinal Encoder (OE)\n",
    " \n",
    "- Suitable when the categorical variable has a **natural, meaningful order** (e.g., ratings, education levels).  \n",
    "- Ensure your model can properly handle this **imposed ordinality**.  \n",
    "- Not suitable for **nominal data** where no order exists.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Count Encoder\n",
    "\n",
    "- Captures the **frequency signal** of categories — great for large datasets.  \n",
    "- Rare categories with **low counts** can mislead interpretations.  \n",
    "- Often paired with other encoders or ensemble models for **better stability**.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Binary Encoder\n",
    " \n",
    "- Useful for **medium to high cardinality features** where OHE is impractical.  \n",
    "- Reduces dimensionality efficiently while preserving more information than simple ordinal encoding.  \n",
    "- Ensure binary patterns remain **meaningful to your model**.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Target Encoder\n",
    "\n",
    "- Powerful when there is a **strong relationship** between the category and the target.  \n",
    "- Essential for **complex models** to capture nuanced patterns.  \n",
    "- Always use **smoothing** and **cross-validation** to prevent **overfitting** and **leakage**.  \n",
    "\n",
    "---\n",
    "\n",
    "####  Weight of Evidence (WoE)\n",
    "\n",
    "- Excels in **binary classification tasks**, especially in **financial and risk domains**.  \n",
    "- Transforms categories into a measure of **predictive power**, aiding interpretability.  \n",
    "- Ensure the **target is binary** and apply smoothing for categories with no events to avoid infinite values.  \n",
    "\n",
    "---\n",
    "\n",
    "### General Wisdom\n",
    "\n",
    "1. **Understand Your Data**  \n",
    "   - The best encoding depends heavily on your categorical data and problem context.  \n",
    "\n",
    "2. **Experimentation is Key**  \n",
    "   - There is no universal best method. Test multiple encoders and compare performance.  \n",
    "\n",
    "3. **Guard Against Leakage**  \n",
    "   - Target-based encoders (Target Encoding, WoE) must be applied carefully with proper cross-validation.  \n",
    "\n",
    "4. **Balance Complexity and Interpretability**  \n",
    "   - Complex encodings may boost performance but reduce interpretability.  \n",
    "   - Always align the choice with your project goals.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Categorical Encoding Techniques: Overview\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Ordinal Encoder\n",
    "**How it works:** Converts each category into a unique integer based on order of appearance or alphabetical order.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Simple to implement and understand.  \n",
    "- Preserves order where it might be meaningful.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Imposes an ordinal relationship that may not exist, potentially misleading the model.  \n",
    "- Not suitable for non-ordinal data or models sensitive to numerical relationships.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Tree-based models where ordinal relationships are useful.  \n",
    "- Situations where natural order of categories carries meaningful information.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 2. One-Hot Encoder\n",
    "**How it works:** Creates a separate binary column for each category level, with a 1 indicating presence.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Prevents artificial ordinal relationships.  \n",
    "- Easy to interpret and implement.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Can lead to large increases in dimensionality with high-cardinality features.  \n",
    "- Not efficient for models that inherently handle categorical data.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Linear models or neural networks requiring explicit numeric conversion.  \n",
    "- Datasets with a small number of unique categories.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Binary Encoder\n",
    "**How it works:** Converts categories to ordinal numbers, encodes as binary, and splits digits into separate columns.  \n",
    "\n",
    "**Advantages:**  \n",
    "- More space-efficient than OHE for high-cardinality features.  \n",
    "- Reduces curse of dimensionality.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Introduces a form of ordinality that may not be inherent.  \n",
    "- Binary representation can be less intuitive.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- High-cardinality features where OHE is impractical.  \n",
    "- Models benefiting from reduced dimensionality but unable to exploit categorical nature directly.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 4. BaseN Encoder\n",
    "**How it works:** Generalization of binary encoding using base-N representation for flexible dimensionality control.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Customizable balance between dimensionality and information retention.  \n",
    "- Controls expansion of feature space.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Base selection requires tuning.  \n",
    "- Interpretation can be complex depending on chosen base.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Datasets where neither binary nor OHE is satisfactory.  \n",
    "- Scenarios requiring tunable categorical encoding.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Target Encoder\n",
    "**How it works:** Replaces category with mean of target variable for that category.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Captures information about the target, improving model performance.  \n",
    "- Reduces dimensionality without losing information.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Risk of overfitting and data leakage if not properly regularized.  \n",
    "- Mean calculation must avoid including validation/test sets.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Models capturing the relationship between features and target.  \n",
    "- Categories with a direct relationship to the target variable.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 6. James-Stein Encoder\n",
    "**How it works:** Uses James-Stein estimator to shrink category means towards the global mean, regularizing small samples.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Improves estimates for small categories.  \n",
    "- Prevents overfitting by shrinking extreme values.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- More complex and less intuitive than simpler methods.  \n",
    "- Gains depend on dataset context.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Regression tasks with continuous targets and many small categories.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 7. M-estimate Encoder\n",
    "**How it works:** Simplified target encoding with smoothing to balance category mean and global mean.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Reduces overfitting for small sample categories.  \n",
    "- Simple implementation with a smoothing parameter.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Requires careful tuning of smoothing.  \n",
    "- Can still be prone to data leakage without proper cross-validation.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Target encoding with control over small sample influence.  \n",
    "- Regression and binary classification with categorical features.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 8. Weight of Evidence (WoE)\n",
    "**How it works:** Transforms categories based on log-odds of target = 1 within each category.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Interpretable as odds ratio.  \n",
    "- Handles binary targets naturally.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Only for binary classification.  \n",
    "- Zero-event categories require careful handling.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Credit risk assessment and other binary classification tasks.  \n",
    "- Financial and medical domains requiring interpretability.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 9. Leave One Out Encoder\n",
    "**How it works:** Similar to target encoding but leaves out the current row to reduce overfitting.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Reduces overfitting compared to standard target encoding.  \n",
    "- Maintains category-target relationship.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Computationally intensive.  \n",
    "- May still require additional regularization.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Supervised learning with high risk of target leakage.  \n",
    "- Projects prioritizing predictive accuracy over interpretability.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 10. CatBoost Encoder\n",
    "**How it works:** Advanced leave-one-out encoding with smoothing inspired by CatBoost to reduce overfitting.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Strong performance with categorical variables, especially in tree-based models.  \n",
    "- Sophisticated smoothing to combat overfitting.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Harder to interpret than simpler encoders.  \n",
    "- Performance gains may vary by dataset.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Classification/regression with important categorical features.  \n",
    "- Projects using CatBoost or tree-based models.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 11. Generalized Linear Mixed Model (GLMM) Encoder\n",
    "**How it works:** Uses GLMM to estimate effect of each category on the target, blending encoding with statistical modeling.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Captures complex category-target relationships.  \n",
    "- Statistically rigorous.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Requires more statistical knowledge.  \n",
    "- Computationally intensive.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Biostatistics or social sciences predictive modeling.  \n",
    "- Complex, non-linear relationships between categorical features and target.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 12. Sum Encoder (Effect Encoder)\n",
    "**How it works:** Similar to OHE but uses -1 for reference category, representing effects relative to baseline.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Captures relative effects against baseline, useful in linear models.  \n",
    "- Sometimes more informative than standard OHE.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Can introduce multicollinearity in linear models.  \n",
    "- Interpretation less straightforward than OHE.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Linear regression models needing baseline comparison.  \n",
    "- Situations requiring relative effect analysis.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 13. Polynomial Encoder\n",
    "**How it works:** Encodes categorical variables as orthogonal polynomials to capture non-linear relationships.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Models complex, non-linear category-target relationships.  \n",
    "- Useful for trend analysis in ordered categories.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Harder to interpret.  \n",
    "- Best suited for ordered categorical variables.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Analysis where order matters and relationships are non-linear.  \n",
    "- Regression tasks benefiting from polynomial relationships.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 14. Backward Difference Encoder\n",
    "**How it works:** Encodes categories by calculating difference between each category and preceding one.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Highlights differences between adjacent categories.  \n",
    "- Reduces multicollinearity compared to OHE.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Assumes ordinal relationship, may not always be valid.  \n",
    "- Interpretation can be challenging with non-ordinal data.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Focus on changes between adjacent categories.  \n",
    "- Ordered categorical data with meaningful sequence.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 15. Helmert Encoder\n",
    "**How it works:** Compares each level to mean of subsequent levels for contrast coding.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Useful in statistical analysis, experimental designs.  \n",
    "- Systematic category comparison.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Less intuitive interpretation.  \n",
    "- Assumes an order in categories.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- ANOVA and contrast-based analysis.  \n",
    "- Regression modeling in experimental designs.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 16. Hashing Encoder\n",
    "**How it works:** Uses hash function to encode categories into fixed dimensions, handling new categories dynamically.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Efficient with high-cardinality and large datasets.  \n",
    "- Handles unseen categories.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Possible collisions and loss of information.  \n",
    "- Encoded features are not interpretable.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Text classification, NLP tasks.  \n",
    "- Large or dynamic categorical datasets.  \n",
    "\n",
    "---\n",
    "\n",
    "#### 17. Quantile Encoder\n",
    "**How it works:** Encodes categories based on quantile of target distribution instead of mean.  \n",
    "\n",
    "**Advantages:**  \n",
    "- Captures distributional information within categories.  \n",
    "- Useful for skewed or non-normal targets.  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Requires careful handling to avoid overfitting.  \n",
    "- Interpretation more complex than mean-based encoding.  \n",
    "\n",
    "**Use Cases:**  \n",
    "- Regression tasks where target distribution matters.  \n",
    "- Projects where target mean alone does not capture category-target relationship.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
