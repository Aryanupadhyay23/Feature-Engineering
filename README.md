# Feature Engineering

This repository contains my personal work and experiments in **Feature Engineering**.  
I am sharing notes, examples, and code snippets that cover various techniques used to prepare and transform data for machine learning models.

##  Topics Covered

The repository includes detailed explanations and implementations of:

- **Encoding Categorical Variables**  
  Different encoding techniques (One-Hot, Label Encoding, Target Encoding, etc.) with practical examples.

- **Scikit-learn Column Transformer & Pipeline**  
  Building clean and reusable data-preprocessing workflows.

- **Scikit-learn Deep Dive**  
  Exploring advanced features and best practices of scikit-learn.

- **Discretization (Binning)**  
  Converting continuous features into categorical bins.

- **Handling Missing Data**  
  Strategies for imputing or removing missing values.

- **Feature Scaling**  
  Standardization, Minâ€“Max scaling, Robust scaling, and more.

- **Outlier Detection**  
  Identifying and handling outliers to improve model performance.

- **Feature Transformation**  
  Applying mathematical transformations (log, Box-Cox, Yeo-Johnson, etc.) to improve feature distributions.

##  Goal

The goal of this repository is to create a **comprehensive reference** for feature engineering techniques that can be reused in real-world machine learning projects.

##  Tech Stack
- Python  
- [Scikit-learn](https://scikit-learn.org/)  
- Pandas, NumPy, and other supporting libraries

---

Feel free to explore the code, experiment with the examples, and use these techniques in your own projects!
